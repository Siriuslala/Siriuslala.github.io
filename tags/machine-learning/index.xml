<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Machine Learning on Siriuslala&#39;s Blog!</title>
    <link>http://localhost:1313/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Siriuslala&#39;s Blog!</description>
    <image>
      <title>Siriuslala&#39;s Blog!</title>
      <url>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.133.1</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Feb 2025 15:08:53 +0800</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MM_Interp</title>
      <link>http://localhost:1313/posts/mm_interp/</link>
      <pubDate>Tue, 25 Feb 2025 15:08:53 +0800</pubDate>
      <guid>http://localhost:1313/posts/mm_interp/</guid>
      <description>Resource dataset (GQA) GQA:ANewDataset for Real-World Visual Reasoning and Compositional Question Answering https://cs.stanford.edu/people/dorarad/gqa/index.html image token compression (multimodal image token compression) *AdaFV: Rethinking of Visual-Language alignment for VLM acceleration (FasterVLM) [CLS] Attention is All You Need for Training-FreeVisual Token Pruning: Make VLM Inference Faster Sparsevlm: Visual token sparsification for efficient vision-languag (FastV) An image is worth 1/2 tokens after layer 2: Plug-and-PLay Acceleration for VLLM Inference LLaVA-Mini: Efficient Image and Video</description>
    </item>
    <item>
      <title>Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks</title>
      <link>http://localhost:1313/posts/circuit_tuning/</link>
      <pubDate>Wed, 05 Feb 2025 16:22:33 +0800</pubDate>
      <guid>http://localhost:1313/posts/circuit_tuning/</guid>
      <description>The paper is here.
ArXiv: https://arxiv.org/pdf/2502.06106</description>
    </item>
    <item>
      <title>Possible Research Areas in Mechanistic Interpretability</title>
      <link>http://localhost:1313/posts/mech_interp_research/</link>
      <pubDate>Fri, 06 Sep 2024 22:52:16 +0800</pubDate>
      <guid>http://localhost:1313/posts/mech_interp_research/</guid>
      <description>The Purpose I Write This Blog To get started in mech interp research, we need to have a macro understanding of this area. So I write this blog as a summarization of this field to help you and me choose a research topic. Circuit Discovery Methods basic activation patching (causal mediation/interchange interventions&amp;hellip;) path patching scaling techinques: attribution patching DAS (distributed alignment search) directional activation patching? &amp;#x1f52d; resources inspirition Analyzing Multi-Head</description>
    </item>
    <item>
      <title>Exploring Emotional Features in GPT2-Small</title>
      <link>http://localhost:1313/posts/happy_feats/</link>
      <pubDate>Thu, 29 Aug 2024 15:51:59 +0800</pubDate>
      <guid>http://localhost:1313/posts/happy_feats/</guid>
      <description>&amp;#x1f3b6;Code in this post can be found at the jupyter notebook in my &amp;ldquo;saeExploration&amp;rdquo; repo.
Find features that reflect positive emotions To find the features related to a specific emotion, I write five sentences containing the key words for each emotion. For example, for happy emotions I have:
1 2 3 4 5 prompt_happy = [&amp;#34;I&amp;#39;ll be on a vacation tomorrow and I&amp;#39;m so happy.&amp;#34;, &amp;#34;My mombrings home a new puppy and I&amp;#39;m so happy.</description>
    </item>
    <item>
      <title>A Brief Introduction to Mechanistic Interpretability Research</title>
      <link>http://localhost:1313/posts/mech_interp_resource/</link>
      <pubDate>Wed, 28 Aug 2024 13:12:25 +0800</pubDate>
      <guid>http://localhost:1313/posts/mech_interp_resource/</guid>
      <description>The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challenges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc).</description>
    </item>
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Machine Learning on Siriuslala&#39;s Blog!</title>
    <link>https://Siriuslala.github.io/tags/machine-learning/</link>
    <description>Recent content in Machine Learning on Siriuslala&#39;s Blog!</description>
    <image>
      <title>Siriuslala&#39;s Blog!</title>
      <url>https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.133.1</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 Aug 2024 13:12:25 +0800</lastBuildDate>
    <atom:link href="https://Siriuslala.github.io/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Brief Introduction to Mechanistic Interpretability Research</title>
      <link>https://Siriuslala.github.io/posts/mech_inrterp_resource/</link>
      <pubDate>Wed, 28 Aug 2024 13:12:25 +0800</pubDate>
      <guid>https://Siriuslala.github.io/posts/mech_inrterp_resource/</guid>
      <description>1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc).</description>
    </item>
  </channel>
</rss>

<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Machine Learning | Siriuslala's Blog!</title><meta name=keywords content><meta name=description content="ExampleSite description"><meta name=author content="Me"><link rel=canonical href=https://Siriuslala.github.io/tags/machine-learning/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.4413c2fe10c3ffde2ccee0ba56ebbe7434d016f0dab7817008f33227c9f3f0fa.css integrity="sha256-RBPC/hDD/94szuC6Vuu+dDTQFvDat4FwCPMyJ8nz8Po=" rel="preload stylesheet" as=style><link rel=icon href=https://Siriuslala.github.io/pig.svg><link rel=icon type=image/png sizes=16x16 href=https://Siriuslala.github.io/pig.svg><link rel=icon type=image/png sizes=32x32 href=https://Siriuslala.github.io/pig.svg><link rel=apple-touch-icon href=https://Siriuslala.github.io/pig.svg><link rel=mask-icon href=https://Siriuslala.github.io/pig.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://Siriuslala.github.io/tags/machine-learning/index.xml><link rel=alternate hreflang=en href=https://Siriuslala.github.io/tags/machine-learning/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}.formula{width:100%;overflow-x:auto}</style><meta property="og:title" content="Machine Learning"><meta property="og:description" content="ExampleSite description"><meta property="og:type" content="website"><meta property="og:url" content="https://Siriuslala.github.io/tags/machine-learning/"><meta property="og:image" content="https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Machine Learning"><meta name=twitter:description content="ExampleSite description"></head><body class=list id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://Siriuslala.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://Siriuslala.github.io/pig.svg alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Siriuslala.github.io/ title=Posts><span>Posts</span></a></li><li><a href=https://Siriuslala.github.io/about/ title=About><span>About</span></a></li><li><a href=https://Siriuslala.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://Siriuslala.github.io/faq/ title=FAQ><span>FAQ</span></a></li><li><a href=https://Siriuslala.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://Siriuslala.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><header class=page-header><div class=breadcrumbs><a href=https://Siriuslala.github.io/>Home</a>&nbsp;¬ª&nbsp;<a href=https://Siriuslala.github.io/tags/>Tags</a></div><h1>Machine Learning
<a href=/tags/machine-learning/index.xml title=RSS aria-label=RSS><svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" height="23"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></h1></header><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Interpretability (& other areas) for Multimodal Models</h2></header><div class=entry-content><p>üí° This post is¬†initially focused on interpretability for multimodal models, while later a lot of papers in other fields are included, just for convenience.
Resource Interpretability for MLLMs survey A Survey on Mechanistic Interpretability for Multi-Modal Foundation Models Sparks of Explainability Recent Advancements in Explaining Large Vision Models Awesome LMMs Mechanistic Interpretability probing Probing Multimodal Large Language Models for Global and Local Semantic Representations representation Zoom in: An introduction to circuits Multimodal Neurons in Artificial Neural Networks Interpreting CLIP‚Äôs Image Representation via Text-Based Decomposition Interpreting the Second-Order Effects of Neurons in CLIP CLIP‰∏çÂêåÂ±Ç Multimodal Neurons in Pretrained Text-Only Transformers Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers? circuit **(causal tracing) Understanding Information Storage and Transfer in Multi-modal Large Language Models Automatic Discovery of Visual Circuits Towards Vision-Language Mechanistic Interpretability: A Causal Tracing Tool for BLIP SAE Case study: Interpreting, manipulating, and controlling clip with sparse autoencoders Towards multimodal interpretability: Learning sparse interpretable features in vision transformers Discover-then-Name: Task-Agnostic Concept Bottlenecks via Automated Concept Discovery visualization VisualizerÔºÅÁÆÄÂåñ‰Ω†ÁöÑVision TransformerÂèØËßÜÂåñÔºÅ (DVT) Denoising Vision Transformers Token Activation Map to Visually Explain Multimodal LLMs LVLM-Intrepret: An Interpretability Tool for Large Vision Language Models Transformer Interpretability Beyond Attention Visualization others **Towards interpreting visual information processing in vision-language models demo (dogit lens) Laying the Foundations for Vision and Multimodal Mechanistic Interpretability & Open Problems Transformer feed-forward layers build predictions by promoting concepts in the vocabulary space Skip-It? Theoretical Conditions for Layer Skipping in Vision-Language Models tools VLM-Lens information flow **Cross-modal Information Flow in Multimodal Large Language Models *From Redundancy to Relevance: Information Flow in LVLMs Across Reasoning Tasks *What‚Äôs in the Image? A Deep-Dive into the Vision of Vision Language Models The Narrow Gate: Localized Image-Text Communication in Vision-Language Models Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models Lifting the Veil on Visual Information Flow in MLLMs: Unlocking Pathways to Faster Inference analyses on MLLMs Learning to See Before Seeing: Demystifying LLM Visual Priors from Language Pre-training Lost in Embeddings: Information Loss in Vision‚ÄìLanguage Models Words or Vision: Do Vision-Language Models Have Blind Faith in Text? Forgotten Polygons: Multimodal Large Language Models are Shape-Blind Vision Transformers Need Registers On the rankability of visual embeddings Other fields of MLLMs visual pretraining
...</p></div><footer class=entry-footer><span title='2025-02-25 15:08:53 +0800 CST'>February 25, 2025</span>&nbsp;¬∑&nbsp;7 min&nbsp;¬∑&nbsp;3296 words&nbsp;¬∑&nbsp;Sirius</footer><a class=entry-link aria-label="post link to Interpretability (& other areas) for Multimodal Models" href=https://Siriuslala.github.io/posts/mm_interp/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks</h2></header><div class=entry-content><p>ArXiv(old version): https://arxiv.org/pdf/2502.06106</p></div><footer class=entry-footer><span title='2025-02-05 16:22:33 +0800 CST'>February 5, 2025</span>&nbsp;¬∑&nbsp;1 min&nbsp;¬∑&nbsp;3 words&nbsp;¬∑&nbsp;Sirius</footer><a class=entry-link aria-label="post link to Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks" href=https://Siriuslala.github.io/posts/circuit_tuning/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Possible Research Areas in Mechanistic Interpretability</h2></header><div class=entry-content><p>üí° This post is mainly focused on text models. For multi-modal models, please refer to this post.
The Purpose I Write This Blog To get started in mech interp research, we need to have a macro understanding of this area. So I write this blog as a summarization of this field to help you and me choose a research topic.
Circuit Discovery Methods basic activation patching (causal mediation/interchange interventions‚Ä¶) path patching scaling techinques: attribution patching DAS (distributed alignment search) directional activation patching? üî≠ resources inspirition Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned what is circuit discovery? Towards Best Practices of Activation Patching in Language Models: Metrics and Methods How to use and interpret activation patching representative work activation patching Investigating gender bias in language models using causal mediation analysis (ROME) Locating and Editing Factual Associations in GPT Causal Scrubbing: a method for rigorously testing interpretability hypotheses (AtP) Attribution patching: Activation patching at industrial scale AtP*: An efficient and scalable method for localizing llm behaviour to components path patching (ACDC) Towards Automated Circuit Discovery for Mechanistic Interpretability (EAP) Attribution Patching Outperforms Automated Circuit Discovery (EAP-IG) Have faith in faithfulness: Going beyond circuit overlap when finding model mechanisms Localizing Model Behavior with Path Patching distributed alignment search (DAS) Finding Alignments Between Interpretable Causal Variables and Distributed Neural Representations Interpretability at Scale: Identifying Causal Mechanisms in Alpaca new Using SAE Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models Automatically Identifying Local and Global Circuits with Linear Computation Graphs Contextual Decomposition Mechanistic Interpretation through Contextual Decomposition in Transformers Edge Pruning ? Finding Transformer Circuits with Edge Pruning Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning attribution graph see Applications in the Dictionary Learning section Evaluation lack of ground truth
...</p></div><footer class=entry-footer><span title='2024-09-06 22:52:16 +0800 CST'>September 6, 2024</span>&nbsp;¬∑&nbsp;7 min&nbsp;¬∑&nbsp;3254 words&nbsp;¬∑&nbsp;Sirius</footer><a class=entry-link aria-label="post link to Possible Research Areas in Mechanistic Interpretability" href=https://Siriuslala.github.io/posts/mech_interp_research/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>Exploring Emotional Features in GPT2-Small</h2></header><div class=entry-content><p>üé∂Code in this post can be found at the jupyter notebook in my ‚ÄúsaeExploration‚Äù repo.
Find features that reflect positive emotions To find the features related to a specific emotion, I write five sentences containing the key words for each emotion. For example, for happy emotions I have:
1 2 3 4 5 prompt_happy = ["I'll be on a vacation tomorrow and I'm so happy.", "My mombrings home a new puppy and I'm so happy.", "I'm so glad I got the job I wanted.", "I feel so happy when I'm with my friends.", "I'm so happy I got the promotion I wanted.",] I choose to look for features that reflect happiness and sadness. Apart from that, I also wonder if the feature that reflects excitedness has something to do with the one that reflects happiness (they are alike from the semantic level at least.)
...</p></div><footer class=entry-footer><span title='2024-08-29 15:51:59 +0800 CST'>August 29, 2024</span>&nbsp;¬∑&nbsp;6 min&nbsp;¬∑&nbsp;1114 words&nbsp;¬∑&nbsp;Sirius</footer><a class=entry-link aria-label="post link to Exploring Emotional Features in GPT2-Small" href=https://Siriuslala.github.io/posts/happy_feats/></a></article><article class="post-entry tag-entry"><header class=entry-header><h2 class=entry-hint-parent>A Brief Introduction to Mechanistic Interpretability Research</h2></header><div class=entry-content><p>‚ö†Ô∏è Warnings
This post was written when I first delved into this area, and it hasn‚Äôt been updated for a long time. Thus there might be a lot of errors. I‚Äôm still interested in interpretability and its applications. I‚Äôll write something new and interesting later ~ üí° This post is accompanied with another post, which contains specific content in this area.
...</p></div><footer class=entry-footer><span title='2024-08-28 13:12:25 +0800 CST'>August 28, 2024</span>&nbsp;¬∑&nbsp;15 min&nbsp;¬∑&nbsp;3185 words&nbsp;¬∑&nbsp;Sirius</footer><a class=entry-link aria-label="post link to A Brief Introduction to Mechanistic Interpretability Research" href=https://Siriuslala.github.io/posts/mech_interp_resource/></a></article></main><footer class=footer><span>&copy; 2026 <a href=https://Siriuslala.github.io/>Siriuslala's Blog!</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
<!doctype html><html lang=en dir=auto><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>My research interests | Siriuslala's Blog!</title><meta name=keywords content><meta name=description content="mechanistic interpretability
Computational Linguistics


Circuit-tuning: A Mechanistic Approach for Understanding Instrinsic Dimension and Fine-tuning Neural Networks


袁老师建议

理论

重新审视可解释性，如何给出一个漂亮的解释（思考mech interp局限性，是否可以突破一下）
上手实验，实践指导理论


实验

实验数据

因为目标不是提性能，所以可以设置一些独特的评价体系和指标，突出可解释性
因果推断的数据（hzy, xsy）







为什么做这个？"><meta name=author content="Me"><link rel=canonical href=http://localhost:1313/posts/my_research_interests/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.4413c2fe10c3ffde2ccee0ba56ebbe7434d016f0dab7817008f33227c9f3f0fa.css integrity="sha256-RBPC/hDD/94szuC6Vuu+dDTQFvDat4FwCPMyJ8nz8Po=" rel="preload stylesheet" as=style><link rel=icon href=http://localhost:1313/pig.svg><link rel=icon type=image/png sizes=16x16 href=http://localhost:1313/pig.svg><link rel=icon type=image/png sizes=32x32 href=http://localhost:1313/pig.svg><link rel=apple-touch-icon href=http://localhost:1313/pig.svg><link rel=mask-icon href=http://localhost:1313/pig.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=http://localhost:1313/posts/my_research_interests/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=JetBrains+Mono:ital,wght@0,100..800;1,100..800&display=swap" rel=stylesheet><script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]],processEscapes:!0,processEnvironments:!0},options:{skipHtmlTags:["script","noscript","style","textarea","pre"]}},window.addEventListener("load",e=>{document.querySelectorAll("mjx-container").forEach(function(e){e.parentElement.classList+="has-jax"})})</script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}.formula{width:100%;overflow-x:auto}</style><meta property="og:title" content="My research interests"><meta property="og:description" content="mechanistic interpretability
Computational Linguistics


Circuit-tuning: A Mechanistic Approach for Understanding Instrinsic Dimension and Fine-tuning Neural Networks


袁老师建议

理论

重新审视可解释性，如何给出一个漂亮的解释（思考mech interp局限性，是否可以突破一下）
上手实验，实践指导理论


实验

实验数据

因为目标不是提性能，所以可以设置一些独特的评价体系和指标，突出可解释性
因果推断的数据（hzy, xsy）







为什么做这个？"><meta property="og:type" content="article"><meta property="og:url" content="http://localhost:1313/posts/my_research_interests/"><meta property="og:image" content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-09-27T17:07:06+08:00"><meta property="article:modified_time" content="2024-09-27T17:07:06+08:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="My research interests"><meta name=twitter:description content="mechanistic interpretability
Computational Linguistics


Circuit-tuning: A Mechanistic Approach for Understanding Instrinsic Dimension and Fine-tuning Neural Networks


袁老师建议

理论

重新审视可解释性，如何给出一个漂亮的解释（思考mech interp局限性，是否可以突破一下）
上手实验，实践指导理论


实验

实验数据

因为目标不是提性能，所以可以设置一些独特的评价体系和指标，突出可解释性
因果推断的数据（hzy, xsy）







为什么做这个？"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"http://localhost:1313/posts/"},{"@type":"ListItem","position":2,"name":"My research interests","item":"http://localhost:1313/posts/my_research_interests/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"My research interests","name":"My research interests","description":"mechanistic interpretability Computational Linguistics Circuit-tuning: A Mechanistic Approach for Understanding Instrinsic Dimension and Fine-tuning Neural Networks\n袁老师建议\n理论 重新审视可解释性，如何给出一个漂亮的解释（思考mech interp局限性，是否可以突破一下） 上手实验，实践指导理论 实验 实验数据 因为目标不是提性能，所以可以设置一些独特的评价体系和指标，突出可解释性 因果推断的数据（hzy, xsy） 为什么做这个？\n","keywords":[],"articleBody":"mechanistic interpretability Computational Linguistics Circuit-tuning: A Mechanistic Approach for Understanding Instrinsic Dimension and Fine-tuning Neural Networks\n袁老师建议\n理论 重新审视可解释性，如何给出一个漂亮的解释（思考mech interp局限性，是否可以突破一下） 上手实验，实践指导理论 实验 实验数据 因为目标不是提性能，所以可以设置一些独特的评价体系和指标，突出可解释性 因果推断的数据（hzy, xsy） 为什么做这个？\n现有问题/motivation 全量微调耗费计算资源，对于某些特定领域的任务，只有一部分参数需要微调； 缺乏对微调机理的探究，不知道在微调的过程中发生了什么，不知道微调哪些参数，导致出现很多问题，如灾难性遗忘等； intrinsic dimension的概念在LoRA中得到印证，而mech interp领域的ciruit discovery也有类似的想法，在做法上与LoRA也有共通之处 lora只是借用了 intrinsic dimension 的思想，而 intrinsic dimension 究竟是什么缺乏深入的研究； 方法 机理可解释性 贡献 从mech interp的角度入手，提供一种更深入的理解intrinsic dimension的新方法； 提出表征冗余和前向冗余的概念，并分析了因果干预方法（IE 指标）的合理性； 提出广义 intrinsic dimension 的定义； 分析circuit discovery与AdaLoRA在特征选取上殊途同归； 结合神经科学，提出circuit-tuning，先剪枝(pruning)后微调，作为一种PEFT的新方法，并通过实验证明有效性； 缓解灾难性遗忘； 提供了理解微调过程（Hebbian Learning）(以及训练动力学（训练动态？）?) 的新视角，理解人脑的学习过程 ； 整体逻辑 intrinsic dimension 首次提出的原因是作者认为模型参数存在冗余。在 mech interp 的理论框架下，我认为冗余指的是计算图中的节点冗余。那么： 节点冗余的定义是什么？怎么判断一个节点是否冗余？ 冗余的分类有哪些，各自的来源是什么？ 冗余的检测方法是什么？ 论证思路 前提假设（特征表征空间，特征向量；特定任务下特征冗余） 提出两个概念：表征冗余和前向冗余。阐述各自冗余的来源和冗余的判定方法 定义: 节点冗余 = 表征冗余 + 前向冗余 定义：intrinsic dimension 为其映射得到的表征空间中不冗余节点的个数 论述 circuit discovery 中用到的因果干预方法满足节点冗余的判定条件 由于LoRA是应用intrinsic dimension这一概念进行实践的典型案例，所以从mech interp的角度解释LoRA，并将LoRA与circuit discovery作类比，论证共通之处，最终证明最初猜想的合理性 在理论猜想的指导下，实现circuit-tuning，从而反向论证猜想的合理性 前置（背景）\nmech interp neuron -\u003e feature circuit circuit discovery intrinsic dimension intrinsic dimension The Lottery Ticket Hypothesis … neuron science sparse coding v.s. population coding（为 superposition 提供依据） population … 2000 Information processing with population codes 2015 Neural population coding: combining insights from microscopic and mass signals sparse … BAAI 神经系统的 5 种编码方式与解码 人脑中不同区域分管不同功能；建模成图结构 hebbian learning 及反例（为后续分析边的增强以及为何用 edge patching 做准备） non-Hebbian volume learning mechanism volume learning 的科普（定义很好）：Neural eavesdropping -\u003e 用来解释使用 edge patching 的缘由 volume learning 的定义和模型 (2005) Study of Nitric Oxide Effect in the Hebbian Learning: Towards a Diffusive Hebb’s Law volume learning 的定义和模型 (2009) Can Hebbian Volume Learning Explain Discontinuities in Cortical Maps? (DOI: 10.1162/089976699300016115) volume learning 形式化和机理探究 (2009) A COMPUTATIONAL STUDY OF THE DIFFUSE NEIGHBOURHOODS IN BIOLOGICAL AND ARTIFICIAL NEURAL NETWORKS “An intrinsic feature of the NO diffusion is the formation of not-wired neighbourhoods, diffuse neighbourhoods (DNB), which supports the emerging of complex structures.” volume learning 的定义和模型 (2015) Nitric Oxide Diffusion and Multi-compartmental Systems: Modeling and Implications ??? volume learning 的定义和模型 Volume Learning: Signaling Covariance Through Neural Tissue 用进废退（为后续分析引入额外参数拟合任务会造成其他能力的遗忘） … Finetuning full PEFT Lora, AdaLora mask操作的定义 理论 Provide an understanding of intrinsic dimension using mech interp\n猜想：The computational graph of a model is $G$. Given a weight matrix $W$ and a circuit $C \\subseteq G$ corresponding to a specific task $T$ with a granularity at the neuron level, the intrinsic dimenison of $W$ is equivalent to the number of nodes in $C$ which exist in the vector space projected by $W$.\n假设\n把模型看出计算图\nLinear feature hypothesis: “Let’s call a neural network representation linear if features correspond to directions in activation space.” – toy model\n表征的定义：representation -\u003e vector space SLU-3.2 两个原则：Composition as Addition \u0026 Intensity as Scaling – July Updates Superposition\nthe phenomenon of polysemanticity 在特征空间正交基集合 $\\mathbf{E}$ 的定义 假设表征空间维度为m，则 $\\mathbf{E} = ({\\vec{e_{1}}, \\vec{e_{2}}, …, \\vec{e_{m}}})$ 为一组相互正交的基底 因为存在 superposition，所以特征往往不会和神经元对应的basis对齐，由此引出特征向量 SLU-3.4 特征向量的定义 特征 $f$ 是向量空间中的一个方向，其特征向量 $\\vec{v_{f}}$ 是正交基底的线性组合，即 $$ \\vec{v_{f}} = \\sum_{i=1}^{m}c_{i}\\vec{e_{i}} = c_{1}\\vec{e_{1}} + c_{2}\\vec{e_{2}} +…+ c_{m}\\vec{e_{m}} $$ ($c_{i}$为系数，$|ci|≤1$ 且 $\\sum_{i=1}^{k}ci^{2}=1$)。 All features represented in a model is $\\mathcal{F}$. Given a task $T$ with $\\mathcal{D_{T}} = ({x_{1}, x_{2}, …, x_{t}})$ which consists of $t$ samples that follows a specific data distribution, the features of $T$ is $\\mathcal{F_{T}}\\subsetneqq \\mathcal{F}$.\nintrinsic dimension exists in a model when it comes to a specific task.\n定理/猜想/命题/定义\n讨论\n最终的目的是提出一种新的 intrinsic dimension 的定义和理解方法，对于某个参数 W，希望将 intrinsic dimension 理解为通过 W 映射得到的表征空间中不冗余节点的个数。 可从 AdaLoRA的重要性分数（IE指标）的形式出发：$|w\\nabla_{w}\\mathcal{L}|$。两部分：参数原有的大小和损失函数关于参数的梯度。由此提出两个概念：表征冗余和前向冗余。 表征冗余指的是表征空间的维度存在冗余，某一维度的值很小，则该维度冗余； 前向冗余指的是表征空间某一维度上的值在参与后续计算的过程中影响力被削弱，对最终结果没什么影响，所以也是冗余； 提出节点冗余的判据：需要表征冗余和前向冗余同时存在。 讨论 IE 作为节点贡献判断的合理性 正式定义 intrinsic dimension 论述 AdaLoRA 中重要性分数与 circuit discovery 中 IE 指标的等价性。 ReLU的特征选择机理（后续在实验中证明）\n在模型中设置 ReLu，会鼓励激活值变大？ 前置\n讨论 intrinsic dimension，针对的是神经网络中的某一个参数矩阵中参数的冗余性。我们可以通过考察经过该矩阵映射后得到的表征$H$来研究其冗余性。我们若将表征 $H=({h_{1}, h_{2}, …, h_{m}}) \\in \\mathbb{R}^{D}(D=m)$视为研究主体，则可将考察的参数矩阵记为$W_{pre}\\in \\mathbb{R}^{m \\times n}$. I（定义 特定任务下表征存在冗余：representation redundancy）\nGiven a task $T$ and an input $x\\in T$. 假设$x$所含的特征 $\\mathcal{F_{x}} = (f_{1},f_{2}, …, f_{t}) \\subseteq F_{T}$ 对应的特征方向为 $ \\mathbf{V_{x}} = ({ \\vec{v_{f_{1}}}, \\vec{v_{f_{2}}}, …, \\vec{v_{f_{t}}} }) $, 且特征的激活值为 $ A_{x} = ({ a_{f_{1}}, a_{f_{2}}, …, a_{f_{t}} }) $, 则表征空间内 $\\vec{e_{i}}$ 方向上的强度 $a_{i}$ 可以表示为： $$ a_{i} = (\\sum_{i=1}^{t} a_{f_{i}}\\vec{v_{f_{i}}} ) \\cdot \\vec{e_{i}} $$\n表征冗余的前提假设\n特征的稀疏性(sparsity): 一条数据往往只包含个别的几个特征 Toy Models of Superposition 特定任务下用到的特征数量有限 (Definition) 特征的语义不变性（semantics preservation of a feature）：Consider a feature $f$ with its feature direction $\\vec{v_{f}} = \\sum_{i=1}^{m}c_{i}\\vec{e_{i}}$. If we set the coefficients in $\\vec{v_{f}}$ which correspond to a set of bases $\\mathbf{E_{r}}$ to zero, then we can get a new vector $\\tilde{\\vec{v_{f}}}$. If the cosine similarity $ cos(\\vec{v_{f}}, \\tilde{\\vec{v_{f}}}) = \\frac{\\vec{v_{f}} \\cdot \\tilde{\\vec{v_{f}}}} {||\\vec{v_{f}}|| \\cdot ||\\tilde{\\vec{v_{f}}}||} \\gt \\delta$ $(\\delta \\in (0, 1])$, then we say $\\tilde{\\vec{v_{f}}}$ has preserved the semantic information in $f$.\n(Definition) 维度冗余（dimension redundancy）：Given a task $T$ with a number of features $\\mathcal{F_{T}}$. Let’s consider a single basis $\\vec{e_{i}}$. For any feature $f$ in $\\mathcal{F_{T}}$, we set the coefficient $c_{i}$ in $\\vec{v_{f}}$ to zero and get the deformed feature direction $\\tilde{\\vec{v_{f}}}$. If $\\vec{e_{i}}$ satisfies: $$ min[cos( \\vec{v_{f_{1}}}, \\tilde{\\vec{v_{f_{1}}}} ), cos( \\vec{v_{f_{2}}}, \\tilde{\\vec{v_{f_{2}}}} ), …, cos( \\vec{v_{f_{|\\mathcal{F_{T}}|}}}, \\tilde{\\vec{v_{f_{|\\mathcal{F_{T}}|}}}} )] \\gt \\delta $$ then $\\vec{e_{i}}$ is called a redundant dimension for representing features in task $T$. Noet that $\\delta \\in (0, 1]$ is the lowerbound for judging whether $\\tilde{\\vec{v_{f}}}$ preserves the semantic information in $f$.\n(Corollary) ：Consider the setup of Definition …. If $\\vec{e_{i}}$ satisfies: $$ max(|\\vec{v_{f_{1}}} \\vec{e_{i}}|,|\\vec{v_{f_{2}}} \\vec{e_{i}}|, …, |\\vec{v_{f_{|\\mathcal{F_{T}}|}}} \\vec{e_{i}}|) \\lt \\sqrt{1-\\delta^{2}} $$ then we say $\\vec{e_{i}}$ is redundant for representing features in task $T$. This is an obvious result from the rigorous definition for dimension redundancy of a single basis in a specific task. Noet that $|\\vec{v_{f_{j}}} \\vec{e_{i}}|$ is the projection of $\\vec{v_{f_{j}}}$ on direction $\\vec{e_{i}}$. Higher $|\\vec{v_{f_{j}}} \\vec{e_{i}}|$ means higher dependency of $\\vec{v_{f_{j}}}$ on $\\vec{e_{i}}$. If some tolerance $\\epsilon \\gt 0$ is allowed, then we can redefine the dimension redundancy in a specific task as: $$ \\sum_{j=1}^{|\\mathcal{F_{T}}|} max(|\\vec{v_{f_{j}}} \\vec{e_{i}}| - \\sqrt{1-\\delta^{2}}, 0) \\lt \\epsilon $$ The weak definition of dimension redundancy requires the total deformation in feature directions that exceeds the lowerbound $\\delta$ for semantics preservation should be limited within a threshold $\\epsilon$.\n维度冗余的概率: From Theorem …, the redundancy probability $P_{r}$ of a single basis $\\vec{e_{i}}$ can be written as: $$ P_{r} = \\prod_{j=1}^{|\\mathcal{F_{T}}|} P(|\\vec{v_{f_{j}}} \\vec{e_{i}}| \\lt \\sqrt{1-\\delta^{2}}) $$ The equation tells us that the probability a basis $\\vec{e_{i}}$ is redundant will decrease with the increasing number of features. On the contrary, the fewer features related to a specific task, the higher the likelihood that a certain basis is redundant, leading to more redundant dimensions in the representation. (Definition) 表征冗余（representation redundancy）：Given a specific task $T$ and its related features $\\mathcal{F_{T}}$, we choose a set of bases $\\mathbf{E_{r}}$ from $\\mathbf{E}$. For every feature $f \\in \\mathcal{F_{T}}$, we set the coefficients in its feature direction $\\vec{v_{f}}$ which correspond to the bases in $\\mathbf{E_{r}}$ to zero and get the deformed feature direction $\\tilde{\\vec{v_{f}}}$. Given a threshold $\\epsilon$ which is the tolerence of deformation which exceeds the upperbound $\\delta$ for semantics preservation. If $\\mathbf{E_{r}}$ satisfies: $$ \\sum_{j=1}^{|\\mathcal{F_{T}}|} max[(\\delta - cos( \\vec{v_{f}}, \\tilde{\\vec{v_{f}}} ) ), 0] \\lt \\epsilon $$ then we say $\\mathbf{E_{r}}$ is a set of redundant bases, and the representation redundancy in $\\mathbb{R}^{m}$ is defined under the choice of $\\mathbf{E_{r}}$. If $|\\mathbf{E_{r}}| = r$, then the value of representation redundancy is equal to $r$.\nThe definition of representation redundancy is actually an extension of Definition … from one-dimensional redundancy to multidimensional redundancy. The difference $\\delta - cos( \\vec{v_{f}}, \\tilde{\\vec{v_{f}}} )$ is used to measure the degree of deformation of feature directions. If the total deformation in feature directions is accepted under the threshold $\\epsilon$, then the influence from the removal of $\\mathbf{E_{r}}$ on the semantic representation of $\\mathcal{F_{T}}$ can be ignored, and the number of useful dimensions for representing $\\mathcal{F_{T}}$ is $m-r$. Johnson–Lindenstrauss lemma（用不用的）\n特别的，when the dimension $D$ of latent space $\\mathbb{R}^{D}$ satisfies $D \\geq |\\mathcal{F_{t}}| $, we can suppose that there is no polysemanticity in $H$. In this situation, the number of features needed is equal to the number of non-zero singular values which is actually the rank of $W_{pre}$.\nintrinsic dimension 最初的定义是解空间的余维度？？？(只是知乎的说法，还要根据原文判断) 是否也规定了输入服从某一种数据分布，也就是对于特定任务而言？这样就可以利用 intrinsic dimension 最初的定义来顺理成章地引入“特定任务T”的前提假设。\n参考\nLORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS ADALORA: ADAPTIVE BUDGET ALLOCATION FOR PARAMETER-EFFICIENT FINE-TUNING PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning Sparse Low-rank Adaptation of Pre-trained Language Models II（定义：前向冗余 forward redundancy）\nIf the representation $H={h_{1}, h_{2}, …, h_{m}}$ is followed by another weight matrix $W^{post} \\in \\mathbb{R}^{l\\times m}$, then the following representation is $ H^{\\prime} = W^{post}H \\in \\mathbb{R}^{D^{\\prime}}(D^{\\prime}=l) $. To investigate into the influence of $H$ on $H^{\\prime}$, the representation $H^{\\prime}$ can also be splited into the sum of influnences of the dimensions in $H$: $$ W^{post}H = \\sum_{i=1}^{m}h_{i}W_{:,i}^{post} $$ 我们发现：$h_{i}$ 对 $H^{\\prime}$ 的影响会受到 $W_{:,i}^{post}$ 的制约。如果 $W_{:,i}^{post}$ 参数值很小，则会削弱 $h_{i}$ 的影响，导致其在后续计算中对最终结果的影响降低。 （定义：前向冗余）给定一个表征 $H$ 和后续的参数 $W^{post}$，我们考察 $H$ 中的某个维度 $i$。给定一个影响力的下界 $\\tau_{f} \\gt 0 $。如果： $$ |W_{:,i}^{post} h_{i}| \\lt \\tau_{f} $$ 我们称表征空间 $\\mathbb{R}^{m}$ 中的维度 $i$ 是前向冗余的。即表征空间 $\\mathbb{R}^{m}$ 存在前向冗余。 III（定义：节点冗余 node redundancy）\nGiven a model $\\mathcal{M}$ and its computational graph $\\mathcal{G}=(\\mathcal{V}, \\mathcal{E})$ in which $\\mathcal{V}$ and $\\mathcal{E}$ represent nodes and edges in $\\mathcal{G}$ respectively, consider a node $n \\in \\mathcal{V}$. A batch of inputs $X = (x_{i})_{i=1}^{p} \\subset \\mathcal{D_T}$ is fed into the model and the activation of $n$ as well as the final output $\\mathcal{M}(X)$ are saved. For each input $x_{i}$, if we replace the value of $n$ with another value $n^{\\prime}$ while keeping other activations in the forward propagation of input $x_{i}$ unchanged, we can get another output $\\mathcal{M}(x_{i})^{\\prime}$. Given a metric $f$ for measuring the difference caused by $n$ between two output distribution and a threshold $\\tau$, we can calculate the contribution $c_{i}(n)$ of node $n$ as: $$ c_{i}(n) = f(n; \\mathcal{M}(x_{i}), \\mathcal{M}(x_{i})^{\\prime})$$ If $$ \\mathbb{E}{x{i}~X}[c_{i}(n)] \u003c \\tau$$ then node $n$ is called a redundant node in $\\mathcal{G}$. 定义：patching （节点冗余的检测） 讨论：因果干预指标 IE 能够合理判断节点冗余（从节点冗余的定义出发） indirect effect: 因果推断里的定义 With the concept of indirect effect from causal intervention, we can estimate the contribution of a node as: $$ IE(n; x_{clean}, x_{noise}) = \\mathcal{L_{m}}(\\mathcal{M}(x_{clean}-do(n\\leftarrow n(x_{noise})))) - \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) $$ To …, […] et al purposed attribution which applies a first-order Taylor expansion to $IE$ at $n = n(x_{clean})$. The $IE$ in attribution patching can be simplified into: $$ IE(n; x_{clean}, x_{noise}) \\approx \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) + (n_{noise}-n_{clean}) \\nabla_{n} \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) - \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) = (n_{noise}-n_{clean}) \\nabla_{n} \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) $$ If we use zero ablation, then IE of node $n$ can be written as: $$ IE(n; x_{clean}) \\approx n \\nabla_{n} \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) $$ This form of IE consists of two parts: $n$ the value of node $n$ on the clean input and $ \\nabla_{n} \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) $ the gradient of the patching metric function $\\mathcal{L_{m}}$ on node $n$ in terms of the clean input. The two parts correspond to the representation redundancy and forward redundancy respectively. Let’s consider a representation in $\\mathbb{R}^{m}$ which consists of a set of nodes $N=(n_{1}, n_{2},…, n_{m}) \\subset \\mathcal{G}$ and focus on the node $n_{i}$: The first part directly serves as a signal for representation redundancy since the maginitude of a neuron is a good indicator for dimension redundancy when we inspect into a representation. The smaller the value of a neuron is, the higher the likelihood that the neuron corresponds to a redundant dimension. This is because the activation of a feature $f$ on a basis $\\vec{e_{i}}$ is directly proportional to the projection of the feature direction $\\vec{v_{f}}$ on $\\vec{e_{i}}$.\nOne thing to note is the case where two features $f_{1}$ and $f_{2}$ are almost in opposite directions and the activations on the shared direction may cancel out each other, which results in a situation that the value of a neuron seems to be small though both of the two features fire on it. While this case may be tricky, Elhage et al show that models prefer to represent anticorrelated features in opposite directions, which means $f_{1}$ and $f_{2}$ may never co-occurr at the same time, so the probability of the above case occurring is very small. As for the second part, it can be written as: $$ \\nabla_{n_{i}} \\mathcal{L_{m}} = \\sum_{j=1}^{l} \\nabla_{n_{j}} \\mathcal{L_{m}} \\cdot \\nabla_{n_{i}} n_{j}(chain rule) $$ in which the node $n_{j}$ in the following vector space $\\mathbb{R}^{l}$ can be written as: $$ n_{j} = \\sum_{i=1}^{m}w_{ji}^{post}n_{i} $$ Thus $$ \\nabla_{n_{i}} \\mathcal{L_{m}} = \\sum_{j=1}^{l} \\nabla_{n_{j}} \\mathcal{L_{m}} \\cdot w_{ji}^{post} $$ 讨论： 判断节点是否冗余，需要度量节点对模型计算过程中的贡献。 我们想判断一个节点是冗余的，如果表征冗余而前向不冗余，则该节点的贡献不容忽视；如果前向冗余而表征不冗余，则该节点的也不能判断为冗余。 From this view, either the represenation redundancy or the forward redundancy is not sufficient when measuring the contribution of a node. 节点冗余的充分条件是表征冗余和前向冗余同时存在。 IV（定义 intrinsic dimension）\nWhether a node is redundant or not is determined by $W^{pre}$ and $W^{post}$, or even parameters several layers away. Circuit discovery 通过 IE 来度量节点的贡献。IE 小于阈值，则说明该节点是冗余的。冗余总量为 $d_{r}$，则 intrinsic dimension 为 $D-d_{r}$. (Definition)（广义的 intrinsic dimension: general intrinsic dimension）: 狭义的 intrinsic dimension 是在 neuron level 的范畴下定义的，而广义的 intrinsic dimension 可以定义在任意 granularity 下。对于某一任务，我们选取一个 granularity ，用 IE 来衡量节点的重要性，并选取一个阈值 $\\tau_{IE}$。对于某一个表征 $H \\in \\mathbb{R}^{D}$, 如果 IE(node) 小于阈值，则说明该节点对于该任务情境下而言是冗余的。如果冗余量是 $d_{r}$，则该表征的冗余量为 $D-d_{r}$，也就意味着该表征的映射参数 $W \\in \\mathbb{R}^{m \\times n}$ 在维度 $m$ 上存在参数冗余。 V (命题？)（LoRA 的特征选择 feature selection）\nBy performing singular value decomposition $\\Delta W = U\\Sigma V = \\sum_{i=1}^{r}u_{i}\\sigma_{i}v_{i}$ on weight matrix $\\Delta W$, feature selection is feasible with the optimization of the orthogonal basis in $U,V$ and the mask of singular value $\\sigma_{i}$.\n输入为$x\\in T$, 则 $$\\Delta Wx = U\\Sigma Vx = \\sum_{i=1}^{r}u_{i}\\sigma_{i}v_{i}x = \\sum_{i=1}^{r}(\\sigma_{i}v_{i}x)\\cdot u_{i} = \\sum_{i=1}^{r}a_{i}u_{i} $$ 我们称$a_{i}$为$x$的特征在表征空间内$e_{i}$方向上的强度。 From the decomposition of $\\Delta W$, we can see that all features are forced to be represented only using bases in $U$. Thus the optimization of $\\Delta W$ is to establish a better orthogonal bases $U$ that could minimize the deformation of feature directions and preserve the semantics of task-related features.\nW特征提取: consider the function of $W$ as feature extraction. 变形程度超过阈值的特征被丢弃。这里要重新定义表征冗余，同时去掉多个维度保证形变不超过阈值。 解释/证明\n假设特征$f$所需正交基集合为$e_{f} = { e_{f_{1}}, e_{f_{2}}, …, e_{f_{k}} k\\leq m } $是$m$维表征空间的基底集合$e$的子集,，即特征向量$v_{f}=c_{1}e_{f_{1}}+c_{2}e_{f_{2}}+…+c_{k}e_{f_{k}}$ ($c_{i}$为系数且$|ci|≤1, \\sum_{i=1}^{k}ci^{2}=1$)。若$e_{f}$对应的奇异值集合$\\sigma_{f}={\\sigma_{f_{1}}, \\sigma_{f_{2}}, …, \\sigma_{f_{k}}} $内的某些元素被mask，且mask后的特征方向为$\\tilde{v_{f}}$，我们可以用余弦相似度定义mask操作前后特征的变形程度： $$ cosine_sim = \\frac{v_{f}\\dot \\tilde{v_{f}}}{|v_{f}||\\tilde{v_{f}}|} $$ 给定一个阈值s, 若$cosine_sim \\lt s$，则该特征被丢弃，反之则被选择。 分析\n奇异值不是直接选取特征，而是选取表征空间里的正交基。 ~~ 特征选择的结果是 维度冗余: there is redundancy in the dimensions of the latent space $\\mathbb{R}^{D}(D=m)$ where the features lie. ~~ （目标等价 objective equivalence）: Selecting singular values based on importance scores in AdaLoRA is equivalent to selecting nodes based on indirect effect in circuit discovery. (除了AdaLoRA，是否还有其他的指标)\n感性理解：重要性分数的思想来源于剪枝，而circuit discovery也在做剪枝的事情 证明 指标衡量的是：contribution of a node $n$ to the model’s behavior\n重要性分数\n参考 **Importance estimation for neural network pruning importance score的一般形式，考虑了参数敏感性 Super tickets in pre-trained language models: From model compression to improving generalization transformer里应用importance score Are sixteen heads really better than one? Platon: Pruning large transformer models with upper confidence bound of weight importance importance score的改进：考虑到IS计算结果的不稳定性(AdaLoRA里的滑动平均操作？) **Movement pruning: Adaptive sparsity by fine-tuning 在微调的时候观察参数变化，从而进行剪枝（微调服务于剪枝） 本文是：在剪枝的过程中微调（剪枝服务于微调，剪枝是为了降低微调的计算量） importance score考虑到了参数敏感性，且在推导时用到了泰勒展开；indirect effect在attribution patching里也用到了泰勒展开\n$W^{\\prime}x = (W + \\Delta W)x$ A the j-th neuron $$ n_{j} = \\sum_{i=1}^{r}u_{ij}\\sigma_{i}v_{i}x$$ IS of a parameter $w$: $$I(w) = |w\\nabla_{w}\\mathcal{L}|$$ where $L$ is the loss function(e.g. next token prediction loss). According to this paper, the form of $I$ is actually a approximation of the intervention effect on $w$ when pruning neural networks. Specifically speaking, we can perform sensitivity analysis on a parameter based on the difference in loss induced by removing it. The difference in loss $diff$ can be written as $$|E(D, W)-E(D, W|w=0)|$$ where $E$ is the fitting error, $D$ is the training dataset, $W$ represents the parameters in a model and $w=0$ means removing $w$ by replacing its value with zero. Directly computing $diff$ is inefficient, so […] et al regard $diff$ as a function of $w$ and simplify it by making a first-order Taylor expansion at $w=w_{origin}$, where $w_{origin}$ is the original value of $w$. So it comes to the form of importance score $I$, and $I$ is essentially a simpilified form of indirect effect. logits difference 和 log prob difference 都能推导成 difference in loss (见 Streamlit)\nWhen we apply zero ablation which set $n_{noise}$ to zero, equation () takes almost the same form as equation (): $$ IE(n; x_{clean}, x_{noise}=0) \\approx n_{clean} \\nabla_{n} \\mathcal{L_{m}}(\\mathcal{M}(x_{clean})) $$ Thus, when we inspect in the importance of a neuron in $\\mathbb{R}^{m}$, we can divide it into the importances of singular values in $W \\in \\mathbb{R}^{m \\times n}$ since we can split the value of a neuron into terms including singular values (see). So with chain rule we have: $$ I(\\sigma_{i}) = |\\sigma_{i} \\nabla_{\\sigma_{i}}\\mathcal{L}| = |\\sigma_{i} \\sum_{j=1}^{m} (\\nabla_{n_{j}}\\mathcal{L} \\cdot \\nabla_{\\sigma_{i}}n_{j})| = |\\sigma_{i} \\sum_{j=1}^{m} [\\nabla_{n_{j}}\\mathcal{L} \\cdot (u_{ij}v_{i}^{T}x)]| = | \\sum_{j=1}^{m} [\\nabla_{n_{j}}\\mathcal{L} \\cdot (u_{ij}\\sigma_{i}v_{i}^{T}x)]| = | \\sum_{j=1}^{m} (\\nabla_{n_{j}}\\mathcal{L} \\cdot n_{ji})| = | \\sum_{j=1}^{m} (\\nabla_{n_{j}}\\mathcal{L} \\cdot \\nabla_{n_{ji}}n_{j} \\cdot n_{ji})| = | \\sum_{j=1}^{m} (n_{ji} \\cdot \\nabla_{n_{ji}}\\mathcal{L})| \\approx | \\sum_{j=1}^{m} IE(n_{ji}; x_{clean}, x_{noise}=0)| $$\nRepresentation $N$ can be spilited into iterms corresponding to the singular values of $W^{pre}$. Thus we have: $$ I(\\sigma_{i}) \\approx |IE(N_{i})| $$ $$ N = \\sum_{i=1}^{r}N_{i} $$ We can see the importance score of $\\sigma_{i}$ is approximately equal to the $IE$ of the $i$-th component of the representation $N$ in terms of the SVD on $W^{pre}$.\n参考\nINTRINSIC DIMENSIONALITY EXPLAINS THE EFFECTIVENESS OF LANGUAGE MODEL FINE-TUNING MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES 其他理论分析\nlora A Kernel-Based View of Language Model Fine-Tuning The Impact of LoRA on the Emergence of Clusters in Transformers LoRA Training in the NTK Regime has No Spurious Local Minima Asymmetry in low rank adapters of foundation models The expressive power of low-rank adaptation feature learning Neural Networks can Learn Representations with Gradient Descent 算法\n算法设计\n算法论述\n重要性分数的平滑 $$IE(n)^{(t)} = E_{X^{(t)}}(IE(n, x, x_{noise}))$$ $$IE(n)^{*(t)} = \\overline{IE(n)}^{(t)} \\cdot \\overline{U(n)}^{(t)}$$ $$\\overline{IE(n)}^{(t)} = \\beta_{1}IE(n)^{(t-1)} + (1-\\beta_{1})IE(n)^{(t)}$$ $$\\overline{U(n)}^{(t)} = \\beta_{2}U(n)^{(t-1)} + (1-\\beta_{2})|IE(n)^{(t)} - \\overline{IE(n)}^{(t)}|$$ “随机激活” 细节\n**aggregation method 简单任务（如主谓不一致）：patch activation后，用logit difference/log prob difference John has a pencil John have a pencil 复杂任务（如数学）：整段话输进去，先算IE在一句话中的平均值，再算在样本间的均值 weighted aggregation circuit剪枝的方法 是大于$\\tau$就保留，还是按top_b？ tau如何设置？事先在数据集上求平均？ 是否需要设置类似于budget scheduler的东?(AdaLoRA逐步增加top_b，也就是逐渐增加增量$\\delta W$) **滑动计算IE：抵抗方差，算是一种对circuit discovery的优化 node or edge, or both?(参考 sparse features circuits, AtP*) activation patching path patching 微调哪些部分，是否要与LoRA对应？ soft mask(“随机激活”)? 就是C以外的components随机选取进行更新（参考：SoftNet） 正则化？（灾难性遗忘） MOE routing? 算法流程\nInput: $\\mathcal{D}$: dataset, $\\mathcal{M}$: model, $G$: the computing graph of $\\mathbb{M}$, $\\mathcal{L_{m}}$: metric for measuring indirect effect, $\\tau_{n}$: threshold for nodes in circuit discovery, $\\tau_{e}$: threshold for edges in circuit discovery, T: total number of training steps Output: Fine-tuned model $\\mathcal{M^{\\prime}}$ Set circuit $C \\leftarrow G$\nfor $i=1$ to $T$ do\nsample a mini-batch $X={x_{1}, x_{2}, …, x_{n}} \\sim \\mathcal{D}$\n// circuit discovery\n// patch nodes\nfor node $n \\in C$ do\nif $E_{X}(IE(n, x, x_{noise})) \\lt \\tau_{n}$ then\n$C \\leftarrow C \\backslash n$\nend\nend\n// patch edges\nfor edge $e \\in C$ do\nif $E_{X}(IE(e, x, x_{noise})) \\lt \\tau_{e}$ then\n$C \\leftarrow C \\backslash e$\nend\nend\n//edge tuning\nfor edge $e \\in C$ do\nGet parameter $w$ correspond to $e$\nUpdate $w = w - \\eta \\nabla_{w}\\mathcal{L}$\nend\nReset circuit $C \\leftarrow G$\nend\n参考\n(ACDC) Towards Automated Circuit Discovery for Mechanistic Interpretability (attribution patching) Attribution Patching Outperforms Automated Circuit Discovery Attribution patching: Activation patching at industrial scale AtP*: An efficient and scalable method for localizing llm behaviour to components How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model Linear Representations of sentiment in large language models 收敛性证明（可选）\nLipschitz continuity（参考Forget-free Continual Learning with Soft-Winning SubNetworks） Lipschitz gradient continuity: Let $\\theta \\in \\mathbb{R}^{D} = (\\theta_{1}, \\theta_{2}, …, \\theta_{|D|})$. If …, then we have $$ ||\\nabla_{\\theta}f(\\theta^{\\prime}) - \\nabla_{\\theta}f(\\theta)|| \\leq L||\\theta^{\\prime} - \\theta|| $$ where $L$ is Lipschitz constant. If we mask out a set of parameters $\\theta_{mask} \\subset \\theta$, then we have $$ ||\\nabla_{\\theta \\backslash \\theta_{mask}}f(\\theta^{\\prime}) - \\nabla_{\\theta \\backslash \\theta_{mask}}f(\\theta)|| \\lt ||\\nabla_{\\theta}f(\\theta^{\\prime}) - \\nabla_{\\theta}f(\\theta)|| \\leq L||\\theta^{\\prime} - \\theta|| $$ This is because for each masked parameter $\\theta_{i} \\in \\theta_{mask}$, the gradient of it is equal to 0, which leads to a smaller norm for gradient change. Thus a smaller Lipschitz constant $L_{mask} \\lt L$ serves as the upper bound for the change rate of gradients when we mask out a set of unrelevant parameters, which means the training process will be more stable compared with full fine-tuning. circuit-tuning的特性\n缓解 catastrophic forgetting，interpretable 现有方法 memory replay regularization **parameter isolation 理论上解释如何缓解 参考 微调 Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks Understanding Catastrophic Forgetting in Language Models via Implicit Inference Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking lora *(O-LoRA) Orthogonal Subspace Learning for Language Model Continual Learning *(I-LoRA) Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning InfLoRA GSLoRA 持续学习 Recent Advances of Foundation Language Models-based Continual Learning: A Survey **A Comprehensive Survey of Continual Learning: Theory, Method and Application Brain-inspired learning in artificial neural networks: a review 区别与联系\n与LoRA/AdaLoRA有什么区别？ lora不好对W奇异值分解，所以对增量进行微调，而circuit-tuning直接微调原参数 lora选奇异值的最终结果就是选neuron，也就是说lora直接从参数入手，而circuit-tuning先从mech interp的角度发现circuit，找到edge对应的参数，然后微调 与剪枝相比 相似 用到了lottery ticket的思想 区别 剪枝是模型已经有了某个能力，然后剔除与该能力无关的结构（是这样？），而circuit-tuning是在没有该能力的情况下一步步探索 与continual learning中parameter isolation方法的区别 相似 over-parameterized的假设与intrinsic dimension类似 区别 circuit-tuning可扩展到大于neuron的level，而continual learning大多是neural level circuit-tuning从mech interp的角度考虑，本身是一种微调方法，同时附带了缓解灾难性遗忘的功能 circuit-tuning剪枝的指标是IE；而持续学习如CLNP是计算平均激活值，激活值小会被剪掉，或是SoftNet引入了可学习的weight score，根据weight score设置mask continual learining的场景主要是按顺序进行的t个任务，而circuit-tuning则是提供一种微调的思路 参考（相似成果） (CLNP) **Continual learning via neural pruning Forget-free Continual Learning with Soft-Winning SubNetworks 实验设计\ndataset\ntask for small model subject-verb “disagreement” 损失函数 加权似然函数: $p\\in(0, 1]$ gender bias for LLM math, instruction following, code, language transfer, … others safety gender bias(见SAE circuits) model\nsmall model v.s. LLM small: Pythia, GPT-2, Gemma, Phi Pythia: rotary embeddingss large: Mistral, Llama ReLU特征选择\ncircuit-tuning\nsplit granularity: nodes(neurons or heads? 详见SAE circuits, AtP*) acdc? eap: vectors as nodes spc: neurons as nodes (为了跟SAE features作对比) AtP*: neuron level \u0026 vector level ablation methods(zero? mean? ) 见 IOI 论文的讨论 $L$选哪个？logit difference / log prob 是下一个token还是什么？(aggregation method) IE选哪个？标准activation patching/AtP/AtP*/ig threshld evaluation SAE? evaluation\n简单任务 主谓不一致相关指标： circuit相关指标：faithfulness, completeness, …（见sfc） 复杂任务 通用能力 analyses\n主谓一致-\u003e主谓不一致 circuit的变化 intrinsic dimension的验证：看非零奇异值个数以及circuit中neuron的个数 LoRA和circuit-tuning相互验证 通用能力怎么保证？（谁都可以随便选取一部分参数，然后让新的能力占据其原有能力） application\nmodel steering Hebbian Learning\nAI of Brain and Cognitive Sciences: From the Perspective of First Principles 优点和不足\n优点 参数高效 可解释，更精准 缓解灾难性遗忘 不足 需要先找到circuit 计算量大 不像LoRA一样可插拔 难以scale? ICLR 26 rebuttal\n审稿人推荐了持续学习领域的几篇相似文章 Task-Specific Skill Localization in Fine-tuned Language Models Supermasks in Superposition linguistics 语言习得，二语习得 迁移学习 ","wordCount":"8247","inLanguage":"en","image":"http://localhost:1313/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-09-27T17:07:06+08:00","dateModified":"2024-09-27T17:07:06+08:00","author":{"@type":"Person","name":"Me"},"mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:1313/posts/my_research_interests/"},"publisher":{"@type":"Organization","name":"Siriuslala's Blog!","logo":{"@type":"ImageObject","url":"http://localhost:1313/pig.svg"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=http://localhost:1313/ accesskey=h title="Home (Alt + H)"><img src=http://localhost:1313/pig.svg alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=http://localhost:1313/ title=Posts><span>Posts</span></a></li><li><a href=http://localhost:1313/about/ title=About><span>About</span></a></li><li><a href=http://localhost:1313/archives/ title=Archive><span>Archive</span></a></li><li><a href=http://localhost:1313/faq/ title=FAQ><span>FAQ</span></a></li><li><a href=http://localhost:1313/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=http://localhost:1313/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=http://localhost:1313/>Home</a>&nbsp;»&nbsp;<a href=http://localhost:1313/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">My research interests
<span class=entry-hint title=Draft><svg height="35" viewBox="0 -960 960 960" fill="currentColor"><path d="M160-410v-60h3e2v60H160zm0-165v-60h470v60H160zm0-165v-60h470v60H160zm360 580v-123l221-220q9-9 20-13t22-4q12 0 23 4.5t20 13.5l37 37q9 9 13 20t4 22-4.5 22.5T862.09-380L643-160H520zm3e2-263-37-37 37 37zM580-220h38l121-122-18-19-19-18-122 121v38zm141-141-19-18 37 37-18-19z"/></svg></span></h1><div class=post-meta><span title='2024-09-27 17:07:06 +0800 CST'>September 27, 2024</span>&nbsp;·&nbsp;17 min&nbsp;·&nbsp;8247 words&nbsp;·&nbsp;Me</div></header><div class=post-content><h2 id=mechanistic-interpretability>mechanistic interpretability<a hidden class=anchor aria-hidden=true href=#mechanistic-interpretability>#</a></h2><h3 id=computational-linguistics>Computational Linguistics<a hidden class=anchor aria-hidden=true href=#computational-linguistics>#</a></h3><ul><li><p>Circuit-tuning: A Mechanistic Approach for Understanding Instrinsic Dimension and Fine-tuning Neural Networks</p><ul><li><p>袁老师建议</p><ul><li>理论<ul><li>重新审视可解释性，如何给出一个漂亮的解释（思考mech interp局限性，是否可以突破一下）</li><li>上手实验，实践指导理论</li></ul></li><li>实验<ul><li>实验数据<ul><li>因为目标不是提性能，所以可以设置一些独特的评价体系和指标，突出可解释性</li><li>因果推断的数据（hzy, xsy）</li></ul></li></ul></li></ul></li><li><p>为什么做这个？</p><ul><li>现有问题/motivation<ul><li>全量微调耗费计算资源，对于某些特定领域的任务，只有一部分参数需要微调；</li><li>缺乏对微调机理的探究，不知道在微调的过程中发生了什么，不知道微调哪些参数，导致出现很多问题，如灾难性遗忘等；</li><li>intrinsic dimension的概念在LoRA中得到印证，而mech interp领域的ciruit discovery也有类似的想法，在做法上与LoRA也有共通之处</li><li>lora只是借用了 intrinsic dimension 的思想，而 intrinsic dimension 究竟是什么缺乏深入的研究；</li></ul></li><li>方法<ul><li>机理可解释性</li></ul></li><li>贡献<ul><li>从mech interp的角度入手，提供一种更深入的理解intrinsic dimension的新方法；<ul><li>提出表征冗余和前向冗余的概念，并分析了因果干预方法（IE 指标）的合理性；</li><li>提出广义 intrinsic dimension 的定义；</li><li>分析circuit discovery与AdaLoRA在特征选取上殊途同归；</li></ul></li><li>结合神经科学，提出circuit-tuning，先剪枝(pruning)后微调，作为一种PEFT的新方法，并通过实验证明有效性；<ul><li>缓解灾难性遗忘；</li><li>提供了理解微调过程（Hebbian Learning）(以及训练动力学（训练动态？）?) 的新视角，理解人脑的学习过程 ；</li></ul></li></ul></li><li>整体逻辑<ul><li>intrinsic dimension 首次提出的原因是作者认为模型参数存在冗余。在 mech interp 的理论框架下，我认为冗余指的是计算图中的节点冗余。那么：<ul><li>节点冗余的定义是什么？怎么判断一个节点是否冗余？</li><li>冗余的分类有哪些，各自的来源是什么？</li><li>冗余的检测方法是什么？</li></ul></li><li><strong>论证思路</strong><ul><li>前提假设（特征表征空间，特征向量；特定任务下特征冗余）</li><li>提出两个概念：表征冗余和前向冗余。阐述各自冗余的来源和冗余的判定方法</li><li>定义: 节点冗余 = 表征冗余 + 前向冗余</li><li>定义：intrinsic dimension 为其映射得到的表征空间中不冗余节点的个数</li><li>论述 circuit discovery 中用到的因果干预方法满足节点冗余的判定条件</li><li>由于LoRA是应用intrinsic dimension这一概念进行实践的典型案例，所以从mech interp的角度解释LoRA，并将LoRA与circuit discovery作类比，论证共通之处，最终证明最初猜想的合理性</li><li>在理论猜想的指导下，实现circuit-tuning，从而反向论证猜想的合理性</li></ul></li></ul></li></ul></li><li><p>前置（背景）</p><ul><li>mech interp<ul><li>neuron -> feature</li><li>circuit</li><li>circuit discovery</li></ul></li><li>intrinsic dimension<ul><li>intrinsic dimension</li><li>The Lottery Ticket Hypothesis</li><li>&mldr;</li></ul></li><li>neuron science<ul><li>sparse coding v.s. population coding（为 superposition 提供依据）<ul><li>population &mldr;<ul><li>2000 <a href=https://www.nature.com/articles/35039062>Information processing with population codes</a></li><li>2015 <a href=https://pmc.ncbi.nlm.nih.gov/articles/PMC4379382/>Neural population coding: combining insights from microscopic and mass signals</a></li></ul></li><li>sparse &mldr;<ul><li><a href>BAAI</a></li></ul></li><li><a href=https://zhuanlan.zhihu.com/p/655463876>神经系统的 5 种编码方式与解码</a></li></ul></li><li>人脑中不同区域分管不同功能；建模成图结构</li><li>hebbian learning 及反例（为后续分析边的增强以及为何用 edge patching 做准备）<ul><li>non-Hebbian volume learning mechanism<ul><li>volume learning 的科普（定义很好）：<a href>Neural eavesdropping</a> -> 用来解释使用 edge patching 的缘由</li><li>volume learning 的定义和模型 (2005) <a href>Study of Nitric Oxide Effect in the Hebbian Learning: Towards a Diffusive Hebb’s Law</a></li><li>volume learning 的定义和模型 (2009) <a href=https://www.tesble.com/10.1162/089976699300016115>Can Hebbian Volume Learning Explain Discontinuities in Cortical Maps?</a> (DOI: 10.1162/089976699300016115)</li><li>volume learning 形式化和机理探究 (2009) <a href=https://www.dis.ulpgc.es/contenido/investigacion/trabajos_publicados/ICNC_2009_PaperCP.pdf>A COMPUTATIONAL STUDY OF THE DIFFUSE NEIGHBOURHOODS IN BIOLOGICAL AND ARTIFICIAL NEURAL NETWORKS</a><ul><li>&ldquo;An intrinsic feature of the NO diffusion is the formation of not-wired neighbourhoods, diffuse neighbourhoods (DNB), which supports the emerging of complex structures.&rdquo;</li></ul></li><li>volume learning 的定义和模型 (2015) <a href>Nitric Oxide Diffusion and Multi-compartmental Systems: Modeling and Implications</a></li><li>??? volume learning 的定义和模型 <a href=https://link.springer.com/chapter/10.1007/978-1-4615-3254-5_57>Volume Learning: Signaling Covariance Through Neural Tissue</a></li></ul></li></ul></li><li>用进废退（为后续分析引入额外参数拟合任务会造成其他能力的遗忘）</li><li>&mldr;</li></ul></li><li>Finetuning<ul><li>full</li><li>PEFT<ul><li>Lora, AdaLora<ul><li>mask操作的定义</li></ul></li></ul></li></ul></li></ul></li><li><p>理论
Provide an understanding of intrinsic dimension using mech interp</p><ul><li><p>猜想：<del>The computational graph of a model is $G$. Given a weight matrix $W$ and a circuit $C \subseteq G$ corresponding to a specific task $T$ with a granularity at the neuron level, the intrinsic dimenison of $W$ is equivalent to the number of nodes in $C$ which exist in the vector space projected by $W$.</del></p></li><li><p>假设</p><ul><li><p>把模型看出计算图</p></li><li><p>Linear feature hypothesis: &ldquo;Let&rsquo;s call a neural network representation linear if features correspond to directions in activation space.&rdquo; &ndash; <a href=https://transformer-circuits.pub/2022/toy_model/index.html>toy model</a></p><ul><li>表征的定义：representation -> vector space <a href=https://transformer-circuits.pub/2022/solu/index.html>SLU-3.2</a></li><li>两个原则：Composition as Addition & Intensity as Scaling &ndash; <a href=https://transformer-circuits.pub/2024/july-update/index.html#linear-representations>July Updates</a></li></ul></li><li><p>Superposition</p><ul><li>the phenomenon of polysemanticity</li><li>在特征空间正交基集合 $\mathbf{E}$ 的定义<ul><li>假设表征空间维度为m，则 $\mathbf{E} = ({\vec{e_{1}}, \vec{e_{2}}, &mldr;, \vec{e_{m}}})$ 为一组相互正交的基底</li></ul></li><li>因为存在 superposition，所以特征往往不会和神经元对应的basis对齐，由此引出特征向量 <a href=https://transformer-circuits.pub/2022/solu/index.html>SLU-3.4</a></li><li>特征向量的定义<ul><li>特征 $f$ 是向量空间中的一个方向，其特征向量 $\vec{v_{f}}$ 是正交基底的线性组合，即 $$ \vec{v_{f}} = \sum_{i=1}^{m}c_{i}\vec{e_{i}} = c_{1}\vec{e_{1}} + c_{2}\vec{e_{2}} +&mldr;+ c_{m}\vec{e_{m}} $$ ($c_{i}$为系数，$|ci|≤1$ 且 $\sum_{i=1}^{k}ci^{2}=1$)。</li></ul></li></ul></li><li><p>All features represented in a model is $\mathcal{F}$. Given a task $T$ with $\mathcal{D_{T}} = ({x_{1}, x_{2}, &mldr;, x_{t}})$ which consists of $t$ samples that follows a specific data distribution, the features of $T$ is $\mathcal{F_{T}}\subsetneqq \mathcal{F}$.</p></li><li><p>intrinsic dimension exists in a model when it comes to a specific task.</p></li></ul></li><li><p>定理/猜想/命题/定义</p><ul><li><p>讨论</p><ul><li>最终的目的是提出一种新的 intrinsic dimension 的定义和理解方法，对于某个参数 W，希望将 intrinsic dimension 理解为通过 W 映射得到的表征空间中不冗余节点的个数。</li><li>可从 AdaLoRA的重要性分数（IE指标）的形式出发：$|w\nabla_{w}\mathcal{L}|$。两部分：参数原有的大小和损失函数关于参数的梯度。由此提出两个概念：表征冗余和前向冗余。<ul><li>表征冗余指的是表征空间的维度存在冗余，某一维度的值很小，则该维度冗余；</li><li>前向冗余指的是表征空间某一维度上的值在参与后续计算的过程中影响力被削弱，对最终结果没什么影响，所以也是冗余；</li></ul></li><li>提出节点冗余的判据：需要表征冗余和前向冗余同时存在。</li><li>讨论 IE 作为节点贡献判断的合理性</li><li>正式定义 intrinsic dimension</li><li>论述 AdaLoRA 中重要性分数与 circuit discovery 中 IE 指标的等价性。</li></ul></li><li><p>ReLU的特征选择机理（后续在实验中证明）</p><ul><li>在模型中设置 ReLu，会鼓励激活值变大？</li></ul></li><li><p>前置</p><ul><li>讨论 intrinsic dimension，针对的是神经网络中的某一个参数矩阵中参数的冗余性。我们可以通过考察经过该矩阵映射后得到的表征$H$来研究其冗余性。我们若将表征 $H=({h_{1}, h_{2}, &mldr;, h_{m}}) \in \mathbb{R}^{D}(D=m)$视为研究主体，则可将考察的参数矩阵记为$W_{pre}\in \mathbb{R}^{m \times n}$.</li></ul></li><li><p>I（定义 特定任务下表征存在冗余：representation redundancy）</p><ul><li><p>Given a task $T$ and an input $x\in T$. 假设$x$所含的特征 $\mathcal{F_{x}} = (f_{1},f_{2}, &mldr;, f_{t}) \subseteq F_{T}$ 对应的特征方向为 $ \mathbf{V_{x}} = ({ \vec{v_{f_{1}}}, \vec{v_{f_{2}}}, &mldr;, \vec{v_{f_{t}}} }) $, 且特征的激活值为 $ A_{x} = ({ a_{f_{1}}, a_{f_{2}}, &mldr;, a_{f_{t}} }) $, 则表征空间内 $\vec{e_{i}}$ 方向上的强度 $a_{i}$ 可以表示为：
$$ a_{i} = (\sum_{i=1}^{t} a_{f_{i}}\vec{v_{f_{i}}} ) \cdot \vec{e_{i}} $$</p></li><li><p>表征冗余的前提假设</p><ul><li>特征的稀疏性(sparsity): 一条数据往往只包含个别的几个特征 <a href=https://transformer-circuits.pub/2022/toy_model/index.html>Toy Models of Superposition</a></li><li>特定任务下用到的特征数量有限</li></ul></li><li><p>(Definition) 特征的语义不变性（semantics preservation of a feature）：Consider a feature $f$ with its feature direction $\vec{v_{f}} = \sum_{i=1}^{m}c_{i}\vec{e_{i}}$. If we set the coefficients in $\vec{v_{f}}$ which correspond to a set of bases $\mathbf{E_{r}}$ to zero, then we can get a new vector $\tilde{\vec{v_{f}}}$. If the cosine similarity $ cos(\vec{v_{f}}, \tilde{\vec{v_{f}}}) = \frac{\vec{v_{f}} \cdot \tilde{\vec{v_{f}}}} {||\vec{v_{f}}|| \cdot ||\tilde{\vec{v_{f}}}||} \gt \delta$ $(\delta \in (0, 1])$, then we say $\tilde{\vec{v_{f}}}$ has preserved the semantic information in $f$.</p></li><li><p>(Definition) 维度冗余（dimension redundancy）：Given a task $T$ with a number of features $\mathcal{F_{T}}$. Let&rsquo;s consider a single basis $\vec{e_{i}}$. For any feature $f$ in $\mathcal{F_{T}}$, we set the coefficient $c_{i}$ in $\vec{v_{f}}$ to zero and get the deformed feature direction $\tilde{\vec{v_{f}}}$. If $\vec{e_{i}}$ satisfies:
$$ min[cos( \vec{v_{f_{1}}}, \tilde{\vec{v_{f_{1}}}} ), cos( \vec{v_{f_{2}}}, \tilde{\vec{v_{f_{2}}}} ), &mldr;, cos( \vec{v_{f_{|\mathcal{F_{T}}|}}}, \tilde{\vec{v_{f_{|\mathcal{F_{T}}|}}}} )] \gt \delta $$
then $\vec{e_{i}}$ is called a redundant dimension for representing features in task $T$. Noet that $\delta \in (0, 1]$ is the lowerbound for judging whether $\tilde{\vec{v_{f}}}$ preserves the semantic information in $f$.</p></li><li><p>(Corollary) ：Consider the setup of Definition &mldr;. If $\vec{e_{i}}$ satisfies:
$$ max(|\vec{v_{f_{1}}} \vec{e_{i}}|,|\vec{v_{f_{2}}} \vec{e_{i}}|, &mldr;, |\vec{v_{f_{|\mathcal{F_{T}}|}}} \vec{e_{i}}|) \lt \sqrt{1-\delta^{2}} $$
then we say $\vec{e_{i}}$ is redundant for representing features in task $T$.<br>This is an obvious result from the rigorous definition for dimension redundancy of a single basis in a specific task. Noet that $|\vec{v_{f_{j}}} \vec{e_{i}}|$ is the projection of $\vec{v_{f_{j}}}$ on direction $\vec{e_{i}}$. Higher $|\vec{v_{f_{j}}} \vec{e_{i}}|$ means higher dependency of $\vec{v_{f_{j}}}$ on $\vec{e_{i}}$. If some tolerance $\epsilon \gt 0$ is allowed, then we can redefine the dimension redundancy in a specific task as:
$$ \sum_{j=1}^{|\mathcal{F_{T}}|} max(|\vec{v_{f_{j}}} \vec{e_{i}}| - \sqrt{1-\delta^{2}}, 0) \lt \epsilon $$
The weak definition of dimension redundancy requires the total deformation in feature directions that exceeds the lowerbound $\delta$ for semantics preservation should be limited within a threshold $\epsilon$.</p><ul><li>维度冗余的概率: From Theorem &mldr;, the redundancy probability $P_{r}$ of a single basis $\vec{e_{i}}$ can be written as:
$$ P_{r} = \prod_{j=1}^{|\mathcal{F_{T}}|} P(|\vec{v_{f_{j}}} \vec{e_{i}}| \lt \sqrt{1-\delta^{2}}) $$
The equation tells us that the probability a basis $\vec{e_{i}}$ is redundant will decrease with the increasing number of features. On the contrary, the fewer features related to a specific task, the higher the likelihood that a certain basis is redundant, leading to more redundant dimensions in the representation.</li></ul></li><li><p>(Definition) 表征冗余（representation redundancy）：Given a specific task $T$ and its related features $\mathcal{F_{T}}$, we choose a set of bases $\mathbf{E_{r}}$ from $\mathbf{E}$. For every feature $f \in \mathcal{F_{T}}$, we set the coefficients in its feature direction $\vec{v_{f}}$ which correspond to the bases in $\mathbf{E_{r}}$ to zero and get the deformed feature direction $\tilde{\vec{v_{f}}}$. Given a threshold $\epsilon$ which is the tolerence of deformation which exceeds the upperbound $\delta$ for semantics preservation. If $\mathbf{E_{r}}$ satisfies:
$$ \sum_{j=1}^{|\mathcal{F_{T}}|} max[(\delta - cos( \vec{v_{f}}, \tilde{\vec{v_{f}}} ) ), 0] \lt \epsilon $$
then we say $\mathbf{E_{r}}$ is a set of redundant bases, and the representation redundancy in $\mathbb{R}^{m}$ is defined under the choice of $\mathbf{E_{r}}$. If $|\mathbf{E_{r}}| = r$, then the value of representation redundancy is equal to $r$.</p><ul><li>The definition of representation redundancy is actually an extension of Definition &mldr; from one-dimensional redundancy to multidimensional redundancy. The difference $\delta - cos( \vec{v_{f}}, \tilde{\vec{v_{f}}} )$ is used to measure the degree of deformation of feature directions. If the total deformation in feature directions is accepted under the threshold $\epsilon$, then the influence from the removal of $\mathbf{E_{r}}$ on the semantic representation of $\mathcal{F_{T}}$ can be ignored, and the number of useful dimensions for representing $\mathcal{F_{T}}$ is $m-r$.</li></ul></li><li><p>Johnson–Lindenstrauss lemma（用不用的）</p></li><li><p><del>特别的，when the dimension $D$ of latent space $\mathbb{R}^{D}$ satisfies $D \geq |\mathcal{F_{t}}| $, we can suppose that there is no polysemanticity in $H$. In this situation, the number of features needed is equal to the number of non-zero singular values which is actually the rank of $W_{pre}$.</del></p></li><li><p>intrinsic dimension 最初的定义是解空间的余维度？？？(只是知乎的说法，还要根据原文判断) 是否也规定了输入服从某一种数据分布，也就是对于特定任务而言？这样就可以利用 intrinsic dimension 最初的定义来顺理成章地引入“特定任务T”的前提假设。</p></li><li><p>参考</p><ul><li><a href=https://arxiv.org/pdf/2106.09685>LORA: LOW-RANK ADAPTATION OF LARGE LANGUAGE MODELS</a></li><li><a href=https://arxiv.org/pdf/2303.10512>ADALORA: ADAPTIVE BUDGET ALLOCATION FOR PARAMETER-EFFICIENT FINE-TUNING</a></li><li><a href=https://arxiv.org/pdf/2404.02948>PiSSA: Principal Singular Values and Singular Vectors Adaptation of Large Language Models</a></li><li><a href=https://arxiv.org/pdf/2406.09044>MiLoRA: Harnessing Minor Singular Components for Parameter-Efficient LLM Finetuning</a></li><li><a href=https://arxiv.org/pdf/2311.11696>Sparse Low-rank Adaptation of Pre-trained Language Models</a></li></ul></li></ul></li><li><p>II（定义：前向冗余 forward redundancy）</p><ul><li>If the representation $H={h_{1}, h_{2}, &mldr;, h_{m}}$ is followed by another weight matrix $W^{post} \in \mathbb{R}^{l\times m}$, then the following representation is $ H^{\prime} = W^{post}H \in \mathbb{R}^{D^{\prime}}(D^{\prime}=l) $. To investigate into the influence of $H$ on $H^{\prime}$, the representation $H^{\prime}$ can also be splited into the sum of influnences of the dimensions in $H$:
$$ W^{post}H = \sum_{i=1}^{m}h_{i}W_{:,i}^{post} $$
我们发现：$h_{i}$ 对 $H^{\prime}$ 的影响会受到 $W_{:,i}^{post}$ 的制约。如果 $W_{:,i}^{post}$ 参数值很小，则会削弱 $h_{i}$ 的影响，导致其在后续计算中对最终结果的影响降低。</li><li>（定义：前向冗余）给定一个表征 $H$ 和后续的参数 $W^{post}$，我们考察 $H$ 中的某个维度 $i$。给定一个影响力的下界 $\tau_{f} \gt 0 $。如果：
$$ |W_{:,i}^{post} h_{i}| \lt \tau_{f} $$
我们称表征空间 $\mathbb{R}^{m}$ 中的维度 $i$ 是前向冗余的。即表征空间 $\mathbb{R}^{m}$ 存在前向冗余。</li></ul></li><li><p>III（定义：节点冗余 node redundancy）</p><ul><li>Given a model $\mathcal{M}$ and its computational graph $\mathcal{G}=(\mathcal{V}, \mathcal{E})$ in which $\mathcal{V}$ and $\mathcal{E}$ represent nodes and edges in $\mathcal{G}$ respectively, consider a node $n \in \mathcal{V}$. A batch of inputs $X = (x_{i})_{i=1}^{p} \subset \mathcal{D_T}$ is fed into the model and the activation of $n$ as well as the final output $\mathcal{M}(X)$ are saved.</li><li>For each input $x_{i}$, if we replace the value of $n$ with another value $n^{\prime}$ while keeping other activations in the forward propagation of input $x_{i}$ unchanged, we can get another output $\mathcal{M}(x_{i})^{\prime}$. Given a metric $f$ for measuring the difference caused by $n$ between two output distribution and a threshold $\tau$, we can calculate the contribution $c_{i}(n)$ of node $n$ as:
$$ c_{i}(n) = f(n; \mathcal{M}(x_{i}), \mathcal{M}(x_{i})^{\prime})$$
If
$$ \mathbb{E}<em>{x</em>{i}~X}[c_{i}(n)] &lt; \tau$$
then node $n$ is called a redundant node in $\mathcal{G}$.</li><li>定义：patching</li><li>（节点冗余的检测）<ul><li>讨论：因果干预指标 IE 能够合理判断节点冗余（从节点冗余的定义出发）</li><li>indirect effect: 因果推断里的定义</li><li>With the concept of indirect effect from causal intervention, we can estimate the contribution of a node as:
$$ IE(n; x_{clean}, x_{noise}) = \mathcal{L_{m}}(\mathcal{M}(x_{clean}-do(n\leftarrow n(x_{noise})))) - \mathcal{L_{m}}(\mathcal{M}(x_{clean})) $$
To &mldr;, [&mldr;] et al purposed attribution which applies a first-order Taylor expansion to $IE$ at $n = n(x_{clean})$. The $IE$ in attribution patching can be simplified into:</li></ul>$$ IE(n; x_{clean}, x_{noise}) \approx \mathcal{L_{m}}(\mathcal{M}(x_{clean})) + (n_{noise}-n_{clean}) \nabla_{n} \mathcal{L_{m}}(\mathcal{M}(x_{clean})) - \mathcal{L_{m}}(\mathcal{M}(x_{clean})) = (n_{noise}-n_{clean}) \nabla_{n} \mathcal{L_{m}}(\mathcal{M}(x_{clean})) $$
If we use zero ablation, then IE of node $n$ can be written as:
$$ IE(n; x_{clean}) \approx n \nabla_{n} \mathcal{L_{m}}(\mathcal{M}(x_{clean})) $$
This form of IE consists of two parts: $n$ the value of node $n$ on the clean input and $ \nabla_{n} \mathcal{L_{m}}(\mathcal{M}(x_{clean})) $ the gradient of the patching metric function $\mathcal{L_{m}}$ on node $n$ in terms of the clean input. The two parts correspond to the representation redundancy and forward redundancy respectively. Let&rsquo;s consider a representation in $\mathbb{R}^{m}$ which consists of a set of nodes $N=(n_{1}, n_{2},&mldr;, n_{m}) \subset \mathcal{G}$ and focus on the node $n_{i}$:<ul><li>The first part directly serves as a signal for representation redundancy since the maginitude of a neuron is a good indicator for dimension redundancy when we inspect into a representation. The smaller the value of a neuron is, the higher the likelihood that the neuron corresponds to a redundant dimension. This is because the activation of a feature $f$ on a basis $\vec{e_{i}}$ is directly proportional to the projection of the feature direction $\vec{v_{f}}$ on $\vec{e_{i}}$.<br>One thing to note is the case where two features $f_{1}$ and $f_{2}$ are almost in opposite directions and the activations on the shared direction may cancel out each other, which results in a situation that the value of a neuron seems to be small though both of the two features fire on it. While this case may be tricky, <a href=https://transformer-circuits.pub/2022/toy_model/index.html>Elhage</a> et al show that models prefer to represent anticorrelated features in opposite directions, which means $f_{1}$ and $f_{2}$ may never co-occurr at the same time, so the probability of the above case occurring is very small.</li><li>As for the second part, it can be written as:
$$ \nabla_{n_{i}} \mathcal{L_{m}} = \sum_{j=1}^{l} \nabla_{n_{j}} \mathcal{L_{m}} \cdot \nabla_{n_{i}} n_{j}(chain rule) $$
in which the node $n_{j}$ in the following vector space $\mathbb{R}^{l}$ can be written as:
$$ n_{j} = \sum_{i=1}^{m}w_{ji}^{post}n_{i} $$
Thus $$ \nabla_{n_{i}} \mathcal{L_{m}} = \sum_{j=1}^{l} \nabla_{n_{j}} \mathcal{L_{m}} \cdot w_{ji}^{post} $$</li></ul></li><li>讨论：<ul><li>判断节点是否冗余，需要度量节点对模型计算过程中的贡献。</li><li>我们想判断一个节点是冗余的，如果表征冗余而前向不冗余，则该节点的贡献不容忽视；如果前向冗余而表征不冗余，则该节点的也不能判断为冗余。</li><li>From this view, either the represenation redundancy or the forward redundancy is not sufficient when measuring the contribution of a node.</li><li>节点冗余的充分条件是表征冗余和前向冗余同时存在。</li></ul></li></ul></li><li><p>IV（定义 intrinsic dimension）</p><ul><li>Whether a node is redundant or not is determined by $W^{pre}$ and $W^{post}$, or even parameters several layers away.</li><li>Circuit discovery 通过 IE 来度量节点的贡献。IE 小于阈值，则说明该节点是冗余的。冗余总量为 $d_{r}$，则 intrinsic dimension 为 $D-d_{r}$.</li><li>(Definition)（广义的 intrinsic dimension: general intrinsic dimension）: 狭义的 intrinsic dimension 是在 neuron level 的范畴下定义的，而广义的 intrinsic dimension 可以定义在任意 granularity 下。对于某一任务，我们选取一个 granularity ，用 IE 来衡量节点的重要性，并选取一个阈值 $\tau_{IE}$。对于某一个表征 $H \in \mathbb{R}^{D}$, 如果 IE(node) 小于阈值，则说明该节点对于该任务情境下而言是冗余的。如果冗余量是 $d_{r}$，则该表征的冗余量为 $D-d_{r}$，也就意味着该表征的映射参数 $W \in \mathbb{R}^{m \times n}$ 在维度 $m$ 上存在参数冗余。</li></ul></li><li><p>V (命题？)（LoRA 的特征选择 feature selection）</p><ul><li><p>By performing singular value decomposition $\Delta W = U\Sigma V = \sum_{i=1}^{r}u_{i}\sigma_{i}v_{i}$ on weight matrix $\Delta W$, feature selection is feasible with the optimization of the orthogonal basis in $U,V$ and the mask of singular value $\sigma_{i}$.</p><ul><li>输入为$x\in T$, 则 $$\Delta Wx = U\Sigma Vx = \sum_{i=1}^{r}u_{i}\sigma_{i}v_{i}x = \sum_{i=1}^{r}(\sigma_{i}v_{i}x)\cdot u_{i} = \sum_{i=1}^{r}a_{i}u_{i} $$ 我们称$a_{i}$为$x$的特征在表征空间内$e_{i}$方向上的强度。</li></ul></li><li><p>From the decomposition of $\Delta W$, we can see that all features are forced to be represented only using bases in $U$. Thus the optimization of $\Delta W$ is to establish a better orthogonal bases $U$ that could minimize the deformation of feature directions and preserve the semantics of task-related features.</p><ul><li>W特征提取: consider the function of $W$ as feature extraction. 变形程度超过阈值的特征被丢弃。这里要重新定义表征冗余，同时去掉多个维度保证形变不超过阈值。</li></ul></li><li><p>解释/证明</p><ul><li><del>假设特征$f$所需正交基集合为$e_{f} = { e_{f_{1}}, e_{f_{2}}, &mldr;, e_{f_{k}} k\leq m } $是$m$维表征空间的基底集合$e$的子集,，即特征向量$v_{f}=c_{1}e_{f_{1}}+c_{2}e_{f_{2}}+&mldr;+c_{k}e_{f_{k}}$ ($c_{i}$为系数且$|ci|≤1, \sum_{i=1}^{k}ci^{2}=1$)。若$e_{f}$对应的奇异值集合$\sigma_{f}={\sigma_{f_{1}}, \sigma_{f_{2}}, &mldr;, \sigma_{f_{k}}} $内的某些元素被mask，且mask后的特征方向为$\tilde{v_{f}}$，我们可以用余弦相似度定义mask操作前后特征的变形程度：</del>
$$ cosine_sim = \frac{v_{f}\dot \tilde{v_{f}}}{|v_{f}||\tilde{v_{f}}|} $$
给定一个阈值s, 若$cosine_sim \lt s$，则该特征被丢弃，反之则被选择。</li></ul></li><li><p>分析</p><ul><li>奇异值不是直接选取特征，而是选取表征空间里的正交基。</li><li>~~ 特征选择的结果是 维度冗余: there is redundancy in the dimensions of the latent space $\mathbb{R}^{D}(D=m)$ where the features lie. ~~</li></ul></li><li><p>（目标等价 objective equivalence）: Selecting singular values based on importance scores in AdaLoRA is equivalent to selecting nodes based on indirect effect in circuit discovery. (除了AdaLoRA，是否还有其他的指标)</p><ul><li>感性理解：重要性分数的思想来源于剪枝，而circuit discovery也在做剪枝的事情</li><li>证明<ul><li><p>指标衡量的是：contribution of a node $n$ to the model&rsquo;s behavior</p></li><li><p>重要性分数</p><ul><li>参考<ul><li><a href=https://openaccess.thecvf.com/content_CVPR_2019/papers/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.pdf>**Importance estimation for neural network pruning</a><ul><li>importance score的一般形式，考虑了参数敏感性</li></ul></li><li><a href=https://arxiv.org/pdf/2105.12002>Super tickets in pre-trained language models: From model compression to improving generalization</a><ul><li>transformer里应用importance score</li><li><a href=https://proceedings.neurips.cc/paper_files/paper/2019/file/2c601ad9d2ff9bc8b282670cdd54f69f-Paper.pdf>Are sixteen heads really better than one?</a></li></ul></li><li><a href=https://proceedings.mlr.press/v162/zhang22ao/zhang22ao.pdf>Platon: Pruning large transformer models with upper confidence bound of weight importance</a><ul><li>importance score的改进：考虑到IS计算结果的不稳定性(AdaLoRA里的滑动平均操作？)</li></ul></li><li><a href=https://proceedings.neurips.cc/paper_files/paper/2020/file/eae15aabaa768ae4a5993a8a4f4fa6e4-Paper.pdf>**Movement pruning: Adaptive sparsity by fine-tuning</a><ul><li>在微调的时候观察参数变化，从而进行剪枝（微调服务于剪枝）</li><li>本文是：在剪枝的过程中微调（剪枝服务于微调，剪枝是为了降低微调的计算量）</li></ul></li></ul></li></ul></li><li><p>importance score考虑到了参数敏感性，且在推导时用到了泰勒展开；indirect effect在attribution patching里也用到了泰勒展开</p><ul><li>$W^{\prime}x = (W + \Delta W)x$</li><li>A the j-th neuron $$ n_{j} = \sum_{i=1}^{r}u_{ij}\sigma_{i}v_{i}x$$</li><li>IS of a parameter $w$: $$I(w) = |w\nabla_{w}\mathcal{L}|$$ where $L$ is the loss function(e.g. next token prediction loss). According to <a href=https://openaccess.thecvf.com/content_CVPR_2019/papers/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.pdf>this paper</a>, the form of $I$ is actually a approximation of the intervention effect on $w$ when pruning neural networks.
Specifically speaking, we can perform sensitivity analysis on a parameter based on the difference in loss induced by removing it. The difference in loss $diff$ can be written as $$|E(D, W)-E(D, W|w=0)|$$ where $E$ is the fitting error, $D$ is the training dataset, $W$ represents the parameters in a model and $w=0$ means removing $w$ by replacing its value with zero. Directly computing $diff$ is inefficient, so [&mldr;] et al regard $diff$ as a function of $w$ and simplify it by making a first-order Taylor expansion at $w=w_{origin}$, where $w_{origin}$ is the original value of $w$. So it comes to the form of importance score $I$, and $I$ is essentially a simpilified form of indirect effect.</li></ul><p>logits difference 和 log prob difference 都能推导成 difference in loss (见 <a href=https://arena3-chapter1-transformer-interp.streamlit.app/%5B1.4.1%5D_Indirect_Object_Identification>Streamlit</a>)<br>When we apply zero ablation which set $n_{noise}$ to zero, equation () takes almost the same form as equation ():
$$ IE(n; x_{clean}, x_{noise}=0) \approx n_{clean} \nabla_{n} \mathcal{L_{m}}(\mathcal{M}(x_{clean})) $$
Thus, when we inspect in the importance of a neuron in $\mathbb{R}^{m}$, we can divide it into the importances of singular values in $W \in \mathbb{R}^{m \times n}$ since we can split the value of a neuron into terms including singular values (see). So with chain rule we have:
$$ I(\sigma_{i}) = |\sigma_{i} \nabla_{\sigma_{i}}\mathcal{L}| = |\sigma_{i} \sum_{j=1}^{m} (\nabla_{n_{j}}\mathcal{L} \cdot \nabla_{\sigma_{i}}n_{j})| = |\sigma_{i} \sum_{j=1}^{m} [\nabla_{n_{j}}\mathcal{L} \cdot (u_{ij}v_{i}^{T}x)]| = | \sum_{j=1}^{m} [\nabla_{n_{j}}\mathcal{L} \cdot (u_{ij}\sigma_{i}v_{i}^{T}x)]| = | \sum_{j=1}^{m} (\nabla_{n_{j}}\mathcal{L} \cdot n_{ji})| = | \sum_{j=1}^{m} (\nabla_{n_{j}}\mathcal{L} \cdot \nabla_{n_{ji}}n_{j} \cdot n_{ji})| = | \sum_{j=1}^{m} (n_{ji} \cdot \nabla_{n_{ji}}\mathcal{L})| \approx | \sum_{j=1}^{m} IE(n_{ji}; x_{clean}, x_{noise}=0)| $$<br>Representation $N$ can be spilited into iterms corresponding to the singular values of $W^{pre}$. Thus we have:
$$ I(\sigma_{i}) \approx |IE(N_{i})| $$
$$ N = \sum_{i=1}^{r}N_{i} $$
We can see the importance score of $\sigma_{i}$ is approximately equal to the $IE$ of the $i$-th component of the representation $N$ in terms of the SVD on $W^{pre}$.</p></li></ul></li></ul></li><li><p>参考</p><ul><li><a href=https://arxiv.org/pdf/2012.13255>INTRINSIC DIMENSIONALITY EXPLAINS THE EFFECTIVENESS OF LANGUAGE MODEL FINE-TUNING</a></li><li><a href=https://arxiv.org/pdf/1804.08838>MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES</a></li></ul></li></ul></li></ul></li><li><p>其他理论分析</p><ul><li>lora<ul><li><a href=https://proceedings.mlr.press/v202/malladi23a/malladi23a.pdf>A Kernel-Based View of Language Model Fine-Tuning</a></li><li><a href=https://arxiv.org/pdf/2402.15415>The Impact of LoRA on the Emergence of Clusters in Transformers</a></li><li><a href=https://arxiv.org/pdf/2402.11867>LoRA Training in the NTK Regime has No Spurious Local Minima</a></li><li><a href=https://arxiv.org/pdf/2402.16842>Asymmetry in low rank adapters of foundation models</a></li><li><a href=https://arxiv.org/pdf/2310.17513>The expressive power of low-rank adaptation</a></li></ul></li><li>feature learning<ul><li><a href=https://arxiv.org/pdf/2206.15144>Neural Networks can Learn Representations with Gradient Descent</a></li></ul></li></ul></li></ul></li><li><p>算法</p><ul><li><p>算法设计</p><ul><li><p>算法论述</p><ul><li>重要性分数的平滑
$$IE(n)^{(t)} = E_{X^{(t)}}(IE(n, x, x_{noise}))$$
$$IE(n)^{*(t)} = \overline{IE(n)}^{(t)} \cdot \overline{U(n)}^{(t)}$$
$$\overline{IE(n)}^{(t)} = \beta_{1}IE(n)^{(t-1)} + (1-\beta_{1})IE(n)^{(t)}$$
$$\overline{U(n)}^{(t)} = \beta_{2}U(n)^{(t-1)} + (1-\beta_{2})|IE(n)^{(t)} - \overline{IE(n)}^{(t)}|$$</li><li>&ldquo;随机激活&rdquo;</li></ul></li><li><p>细节</p><ul><li>**aggregation method<ul><li>简单任务（如主谓不一致）：patch activation后，用logit difference/log prob difference<ul><li>John <strong>has</strong> a pencil</li><li>John <strong>have</strong> a pencil</li></ul></li><li>复杂任务（如数学）：整段话输进去，先算IE在一句话中的平均值，再算在样本间的均值<ul><li>weighted aggregation</li></ul></li></ul></li><li>circuit剪枝的方法<ul><li>是大于$\tau$就保留，还是按top_b？</li><li>tau如何设置？事先在数据集上求平均？</li><li>是否需要设置类似于budget scheduler的东?(AdaLoRA逐步增加top_b，也就是逐渐增加增量$\delta W$)</li></ul></li><li>**滑动计算IE：抵抗方差，算是一种对circuit discovery的优化</li><li>node or edge, or both?(参考 sparse features circuits, AtP*)<ul><li>activation patching</li><li>path patching</li></ul></li><li>微调哪些部分，是否要与LoRA对应？</li><li>soft mask(&ldquo;随机激活&rdquo;)? 就是C以外的components随机选取进行更新（参考：<a href=https://arxiv.org/pdf/2303.14962>SoftNet</a>）</li><li>正则化？（灾难性遗忘）</li><li>MOE routing?</li></ul></li><li><p>算法流程<br><strong>Input</strong>: $\mathcal{D}$: dataset, $\mathcal{M}$: model, $G$: the computing graph of $\mathbb{M}$, $\mathcal{L_{m}}$: metric for measuring indirect effect, $\tau_{n}$: threshold for nodes in circuit discovery, $\tau_{e}$: threshold for edges in circuit discovery, T: total number of training steps<br><strong>Output</strong>: Fine-tuned model $\mathcal{M^{\prime}}$<br>Set circuit $C \leftarrow G$<br><strong>for</strong> $i=1$ to $T$ <strong>do</strong><br>  sample a mini-batch $X={x_{1}, x_{2}, &mldr;, x_{n}} \sim \mathcal{D}$</p><p>  // circuit discovery<br>  // patch nodes<br>  <strong>for</strong> node $n \in C$ <strong>do</strong><br>    <strong>if</strong> $E_{X}(IE(n, x, x_{noise})) \lt \tau_{n}$ <strong>then</strong><br>      $C \leftarrow C \backslash n$<br>    <strong>end</strong><br>  <strong>end</strong><br>  // patch edges<br>  <strong>for</strong> edge $e \in C$ <strong>do</strong><br>    <strong>if</strong> $E_{X}(IE(e, x, x_{noise})) \lt \tau_{e}$ <strong>then</strong><br>      $C \leftarrow C \backslash e$<br>    <strong>end</strong><br>  <strong>end</strong></p><p>  //edge tuning<br>  <strong>for</strong> edge $e \in C$ <strong>do</strong><br>    Get parameter $w$ correspond to $e$<br>    Update $w = w - \eta \nabla_{w}\mathcal{L}$<br>  <strong>end</strong></p><p>  Reset circuit $C \leftarrow G$<br><strong>end</strong></p></li><li><p>参考</p><ul><li><a href=https://arxiv.org/abs/2304.14997>(ACDC) Towards Automated Circuit Discovery for Mechanistic Interpretability</a></li><li><a href=https://arxiv.org/abs/2310.10348>(attribution patching) Attribution Patching Outperforms Automated Circuit Discovery</a></li><li><a href=https://www.neelnanda.io/mechanistic-interpretability/attribution-patching>Attribution patching: Activation patching at industrial scale</a></li><li><a href=https://arxiv.org/pdf/2403.00745>AtP*: An efficient and scalable method for localizing llm behaviour to components</a></li><li><a href=https://arxiv.org/pdf/2305.00586>How does GPT-2 compute greater-than?: Interpreting mathematical abilities in a pre-trained language model</a></li><li><a href=https://arxiv.org/abs/2310.15154>Linear Representations of sentiment in large language models</a></li></ul></li></ul></li><li><p>收敛性证明（可选）</p><ul><li>Lipschitz continuity（参考<a href=https://arxiv.org/pdf/2303.14962>Forget-free Continual Learning with Soft-Winning SubNetworks</a>）<ul><li>Lipschitz gradient continuity:<ul><li>Let $\theta \in \mathbb{R}^{D} = (\theta_{1}, \theta_{2}, &mldr;, \theta_{|D|})$. If &mldr;, then we have
$$ ||\nabla_{\theta}f(\theta^{\prime}) - \nabla_{\theta}f(\theta)|| \leq L||\theta^{\prime} - \theta|| $$
where $L$ is Lipschitz constant.
If we mask out a set of parameters $\theta_{mask} \subset \theta$, then we have
$$ ||\nabla_{\theta \backslash \theta_{mask}}f(\theta^{\prime}) - \nabla_{\theta \backslash \theta_{mask}}f(\theta)|| \lt ||\nabla_{\theta}f(\theta^{\prime}) - \nabla_{\theta}f(\theta)|| \leq L||\theta^{\prime} - \theta|| $$
This is because for each masked parameter $\theta_{i} \in \theta_{mask}$, the gradient of it is equal to 0, which leads to a smaller norm for gradient change. Thus a smaller Lipschitz constant $L_{mask} \lt L$ serves as the upper bound for the change rate of gradients when we mask out a set of unrelevant parameters, which means the training process will be more stable compared with full fine-tuning.</li></ul></li></ul></li></ul></li><li><p>circuit-tuning的特性</p><ul><li>缓解 catastrophic forgetting，interpretable<ul><li>现有方法<ul><li>memory replay</li><li>regularization</li><li>**parameter isolation</li></ul></li><li>理论上解释如何缓解</li></ul></li><li>参考<ul><li>微调<ul><li><a href=https://arxiv.org/pdf/2311.12786>Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks</a></li><li><a href=https://arxiv.org/pdf/2309.10105>Understanding Catastrophic Forgetting in Language Models via Implicit Inference</a></li><li><a href=https://arxiv.org/pdf/2402.14811>Fine-Tuning Enhances Existing Mechanisms: A Case Study on Entity Tracking</a></li></ul></li><li>lora<ul><li>*<a href=https://arxiv.org/pdf/2310.14152>(O-LoRA) Orthogonal Subspace Learning for Language Model Continual Learning</a></li><li>*<a href=https://arxiv.org/pdf/2402.18865>(I-LoRA) Analyzing and Reducing Catastrophic Forgetting in Parameter Efficient Tuning</a></li><li><a href>InfLoRA</a></li><li><a href>GSLoRA</a></li></ul></li><li>持续学习<ul><li><a href=https://arxiv.org/pdf/2405.18653>Recent Advances of Foundation Language Models-based Continual Learning: A Survey</a></li><li><a href=https://arxiv.org/pdf/2302.00487>**A Comprehensive Survey of Continual Learning: Theory, Method and Application</a></li><li><a href=https://arxiv.org/pdf/2305.11252>Brain-inspired learning in artificial neural networks: a review</a></li></ul></li></ul></li></ul></li><li><p>区别与联系</p><ul><li>与LoRA/AdaLoRA有什么区别？<ul><li>lora不好对W奇异值分解，所以对增量进行微调，而circuit-tuning直接微调原参数</li><li>lora选奇异值的最终结果就是选neuron，也就是说lora直接从参数入手，而circuit-tuning先从mech interp的角度发现circuit，找到edge对应的参数，然后微调</li></ul></li><li>与剪枝相比<ul><li>相似<ul><li>用到了lottery ticket的思想</li></ul></li><li>区别<ul><li>剪枝是模型已经有了某个能力，然后剔除与该能力无关的结构（是这样？），而circuit-tuning是在没有该能力的情况下一步步探索</li></ul></li></ul></li><li>与continual learning中parameter isolation方法的区别<ul><li>相似<ul><li>over-parameterized的假设与intrinsic dimension类似</li></ul></li><li>区别<ul><li>circuit-tuning可扩展到大于neuron的level，而continual learning大多是neural level</li><li>circuit-tuning从mech interp的角度考虑，本身是一种微调方法，同时附带了缓解灾难性遗忘的功能</li><li>circuit-tuning剪枝的指标是IE；而持续学习如CLNP是计算平均激活值，激活值小会被剪掉，或是SoftNet引入了可学习的weight score，根据weight score设置mask</li><li>continual learining的场景主要是按顺序进行的t个任务，而circuit-tuning则是提供一种微调的思路</li></ul></li><li>参考（相似成果）<ul><li><a href=https://arxiv.org/pdf/1903.04476>(CLNP) **Continual learning via neural pruning</a></li><li><a href=https://arxiv.org/pdf/2303.14962>Forget-free Continual Learning with Soft-Winning SubNetworks</a></li></ul></li></ul></li></ul></li></ul></li><li><p>实验设计</p><ul><li><p>dataset</p><ul><li>task<ul><li>for small model<ul><li>subject-verb &ldquo;disagreement&rdquo;<ul><li>损失函数<ul><li>加权似然函数: $p\in(0, 1]$</li></ul></li></ul></li><li>gender bias</li></ul></li><li>for LLM<ul><li>math, instruction following, code, language transfer, &mldr;</li></ul></li><li>others<ul><li>safety</li><li>gender bias(见SAE circuits)</li></ul></li></ul></li></ul></li><li><p>model</p><ul><li>small model v.s. LLM<ul><li>small: Pythia, GPT-2, Gemma, Phi<ul><li><a href=https://arxiv.org/pdf/2304.01373>Pythia</a>: rotary embeddingss</li></ul></li><li>large: Mistral, Llama</li></ul></li></ul></li><li><p>ReLU特征选择</p></li><li><p>circuit-tuning</p><ul><li>split granularity: nodes(neurons or heads? 详见SAE circuits, AtP*)<ul><li>acdc?</li><li>eap: vectors as nodes</li><li>spc: neurons as nodes (为了跟SAE features作对比)</li><li>AtP*: neuron level & vector level</li></ul></li><li>ablation methods(zero? mean? )<ul><li>见 IOI 论文的讨论</li></ul></li><li>$L$选哪个？logit difference / log prob 是下一个token还是什么？(aggregation method)</li><li>IE选哪个？标准activation patching/AtP/AtP*/ig</li><li>threshld</li><li>evaluation</li><li>SAE?</li></ul></li><li><p>evaluation</p><ul><li>简单任务<ul><li>主谓不一致相关指标：</li><li>circuit相关指标：faithfulness, completeness, &mldr;（见sfc）</li></ul></li><li>复杂任务</li><li>通用能力</li></ul></li><li><p>analyses</p><ul><li>主谓一致->主谓不一致 circuit的变化</li><li>intrinsic dimension的验证：看非零奇异值个数以及circuit中neuron的个数</li><li>LoRA和circuit-tuning相互验证</li><li>通用能力怎么保证？（谁都可以随便选取一部分参数，然后让新的能力占据其原有能力）</li></ul></li><li><p>application</p><ul><li>model steering</li></ul></li><li><p>Hebbian Learning</p><ul><li><a href=https://arxiv.org/pdf/2301.08382>AI of Brain and Cognitive Sciences: From the Perspective of First Principles</a></li></ul></li></ul></li><li><p>优点和不足</p><ul><li>优点<ul><li>参数高效</li><li>可解释，更精准</li><li>缓解灾难性遗忘</li></ul></li><li>不足<ul><li>需要先找到circuit</li><li>计算量大</li><li>不像LoRA一样可插拔</li><li>难以scale?</li></ul></li></ul></li></ul></li><li><p>ICLR 26 rebuttal</p><ul><li>审稿人推荐了持续学习领域的几篇相似文章<ul><li><a href=https://arxiv.org/pdf/2302.06600>Task-Specific Skill Localization in Fine-tuned Language Models</a></li><li><a href=https://arxiv.org/pdf/2006.14769>Supermasks in Superposition</a></li></ul></li></ul></li></ul><h3 id=linguistics>linguistics<a hidden class=anchor aria-hidden=true href=#linguistics>#</a></h3><ul><li>语言习得，二语习得<ul><li>迁移学习</li></ul></li></ul></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=http://localhost:1313/posts/%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E5%AD%A6%E7%9A%84%E6%A2%97%E5%92%8C%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E7%9F%A5%E8%AF%86/><span class=title>« Prev</span><br><span>一些语言学的梗和有意思的知识</span>
</a><a class=next href=http://localhost:1313/posts/mech_interp_research/><span class=title>Next »</span><br><span>Possible Research Areas in Mechanistic Interpretability</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share My research interests on x" href="https://x.com/intent/tweet/?text=My%20research%20interests&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f&amp;hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share My research interests on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f&amp;title=My%20research%20interests&amp;summary=My%20research%20interests&amp;source=http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share My research interests on reddit" href="https://reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f&title=My%20research%20interests"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share My research interests on facebook" href="https://facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share My research interests on whatsapp" href="https://api.whatsapp.com/send?text=My%20research%20interests%20-%20http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share My research interests on telegram" href="https://telegram.me/share/url?text=My%20research%20interests&amp;url=http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share My research interests on ycombinator" href="https://news.ycombinator.com/submitlink?t=My%20research%20interests&u=http%3a%2f%2flocalhost%3a1313%2fposts%2fmy_research_interests%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer><div id=tw-comment></div><script>const getStoredTheme=()=>localStorage.getItem("pref-theme")==="light"?"light":"dark",setGiscusTheme=()=>{const e=e=>{const t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:e},"https://giscus.app")};e({setConfig:{theme:getStoredTheme()}})};document.addEventListener("DOMContentLoaded",()=>{const s={src:"https://giscus.app/client.js","data-repo":"Siriuslala/siriuslala.github.io","data-repo-id":"R_kgDOMo4X2w","data-category":"Announcements","data-category-id":"DIC_kwDOMo4X284CiI_8","data-mapping":"pathname","data-strict":"0","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":getStoredTheme(),"data-lang":"en","data-loading":"lazy",crossorigin:"anonymous"},e=document.createElement("script");Object.entries(s).forEach(([t,n])=>e.setAttribute(t,n)),document.querySelector("#tw-comment").appendChild(e);const t=document.querySelector("#theme-toggle");t&&t.addEventListener("click",setGiscusTheme);const n=document.querySelector("#theme-toggle-float");n&&n.addEventListener("click",setGiscusTheme)})</script></article></main><footer class=footer><span>&copy; 2025 <a href=http://localhost:1313/>Siriuslala's Blog!</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>
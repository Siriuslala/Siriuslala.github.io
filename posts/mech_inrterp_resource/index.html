<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>A Brief Introduction to Mechanistic Interpretability Research | Siriuslala's Blog!</title>
<meta name=keywords content="mechanistic interpretability,machine learning"><meta name=description content="1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc)."><meta name=author content="Sirius"><link rel=canonical href=https://Siriuslala.github.io/posts/mech_inrterp_resource/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.e9637dd400af3a8685b10649e8cbac2b676de9b4bada371932c450a82ecbecbd.css integrity="sha256-6WN91ACvOoaFsQZJ6MusK2dt6bS62jcZMsRQqC7L7L0=" rel="preload stylesheet" as=style><link rel=icon href=https://Siriuslala.github.io/pig.png><link rel=icon type=image/png sizes=16x16 href=https://Siriuslala.github.io/pig.png><link rel=icon type=image/png sizes=32x32 href=https://Siriuslala.github.io/pig.png><link rel=apple-touch-icon href=https://Siriuslala.github.io/pig.png><link rel=mask-icon href=https://Siriuslala.github.io/pig.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://Siriuslala.github.io/posts/mech_inrterp_resource/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=text/javascript async src="https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML">MathJax.Hub.Config({tex2jax:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["[[","]]"]],processEscapes:!0,processEnvironments:!0,skipTags:["script","noscript","style","textarea","pre"],TeX:{equationNumbers:{autoNumber:"AMS"},extensions:["AMSmath.js","AMSsymbols.js"]}}}),MathJax.Hub.Queue(function(){var e,t=MathJax.Hub.getAllJax();for(e=0;e<t.length;e+=1)t[e].SourceElement().parentNode.className+=" has-jax"})</script><style>code.has-jax{font:inherit;font-size:100%;background:inherit;border:inherit;color:#515151}</style><meta property="og:title" content="A Brief Introduction to Mechanistic Interpretability Research"><meta property="og:description" content="1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc)."><meta property="og:type" content="article"><meta property="og:url" content="https://Siriuslala.github.io/posts/mech_inrterp_resource/"><meta property="og:image" content="https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-08-28T13:12:25+08:00"><meta property="article:modified_time" content="2024-08-28T13:12:25+08:00"><meta property="og:site_name" content="ExampleSite"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="A Brief Introduction to Mechanistic Interpretability Research"><meta name=twitter:description content="1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc)."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://Siriuslala.github.io/posts/"},{"@type":"ListItem","position":2,"name":"A Brief Introduction to Mechanistic Interpretability Research","item":"https://Siriuslala.github.io/posts/mech_inrterp_resource/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"A Brief Introduction to Mechanistic Interpretability Research","name":"A Brief Introduction to Mechanistic Interpretability Research","description":"1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc).","keywords":["mechanistic interpretability","machine learning"],"articleBody":"1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc). Thus it‚Äôs a little bit difficult for people new to this area to figure out what researchers are really doing.\nTherefore I write this blog to give a brief introduction to mechanistic interpretability without so much of horrible concepts. The blog aims to help you understand the basic ideas, main directions and latest achievements of this field, providing a list of resources to help you get started at the same time!\n2. What is Mechanistic interpretability? Speaking of AI research, neural network is the tool that is used most widely nowadays for its excellent representation and generalization ability. What does a neural network do? It receives an input and gives an output after some calculations. Specifically speaking, it usually gets the representations of an input and maps it to an expected output under a predefined computation graph. From my perspective, neural networks mainly care about two things: create representations to extract features and establishe the relationship between the representations and the output. Why is neural network so popular? An important reason is that the neural network can save a lot of time for researchers to manually design features. For example, for natural language processing (NLP) people often designed features like ‚Äúthe frequency of a word that appears‚Äù or ‚Äúthe co-occurence probabilities‚Äù in the past. Manually designing features caused too much labor, so people choose to use neural networks to find features automatically. As for optimizing, they set a goal of minimizing the loss function and using backforward propagation (BP) to update the parameters of the model. Thus neural networks free our hands and improve performance at the same time.\nAll is well, so why do we concern about interpretability? Though neural networks can extract a lot of features with a high efficiency, we cannot have a clear understanding of what the features really are. For example, we know that a filter with Laplacian operator can extract the edge of an image, but we don‚Äôt know what the features extracted by a convolution layer mean because the parameters of the filters inside are often randomly initialized and optimized using BP algorithm. As a result, features in neural networks are often ambiguous.\nWhy is interpretability important? Actually this statement is controversial because some people say interpretability is bullshitüí©. I‚Äôm not angry about this. Anyway, people‚Äôs taste varies, just like many people enjoy Picasso‚Äôs abstract paintings while I don‚Äôt. Interpretabilty still lacks exploring so it‚Äôs now far from application, and that‚Äôs why some people look down on it. While it is this lack of exploration that excites me most because there are a lot of unknown things waiting for me to discover! Apart from that, interpretabilty is closely related to AI safety because unwanted things like malicious text generated by a language model may be avoided using model steering (a trick using interpretability).\nLast question: what is mechanistic interpretability? Let‚Äôs call it mech interp first because I‚Äôm really tired of typing the full nameüí¶. There seems not to be a rigorous definition, but I here I want to quote the explanation by Chiris Olah:\nMechanistic interpretability seeks to reverse engineer neural networks, similar to how one might reverse engineer a compiled binary computer program.\nAnother thing: there are various of categories of interpretability, such as studies from the geometry perspective or from the game theory and symbol system perspective, which can be found at ICML, ICLR, NeurlPS, etc. When we say mech interp, we often refer to the studies on Transformer-based generative language models now (though the research started before 2017) which will be introduced briefly in the next section.\n3. Basic ideas and research topics 3.1. Find interpretable features 3.2. Circuits 4. Some Useful Resources Here I list some resources that would be helpful for you to get started quickly in the field.\n4.1. Tutorials Arena‚ÄÇA tutorial created and maintained by Callum McDougall et al, providing a guided path for anyone who finds themselves overwhelmed by the amount of technical AI safety content out there. Neel Nanda‚Äôs Tutorial‚ÄÇNeel‚Äôs tutorial for mech interp. Neel Nanda‚Äôs Quickstart Guide‚ÄÇA quick start for mech interp. Neel Nanda‚Äôs remommended papers‚ÄÇSome classic and important papers for mech interp. Neel Nanda‚Äôs problems v1‚ÄÇNeel‚Äôs old questions for mech interp. Neel Nanda‚Äôs problems v2‚ÄÇNeel‚Äôs 200 new questions for mech interp. 4.2. Frameworks and Libraries TransformerLens‚ÄÇA library maintained by Bryce Meyer and created by Neel Nanda.\nSAELens‚ÄÇOriginates from TransformerLens, and is separated from it because of the popularity and importance of SAE.\n4.3. Forums and Communities Transformer Circuits Thread‚ÄÇThe research posts of Anthropic alignment group. Lesswrong‚ÄÇAI Alignment Forum‚ÄÇ4.4. Institutions and Programs MATS‚ÄÇAn independent research and educational seminar program that connects talented scholars with top mentors in the fields of AI alignment, interpretability, and governance. RedWood‚ÄÇ4.5. Blogs Chris Olah‚ÄÇNeel Nanda‚ÄÇArthur Conmy‚ÄÇTrenton Bricken‚ÄÇCallum Mcdougall‚ÄÇ‚Ä¶\n","wordCount":"881","inLanguage":"en","image":"https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E","datePublished":"2024-08-28T13:12:25+08:00","dateModified":"2024-08-28T13:12:25+08:00","author":{"@type":"Person","name":"Sirius"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://Siriuslala.github.io/posts/mech_inrterp_resource/"},"publisher":{"@type":"Organization","name":"Siriuslala's Blog!","logo":{"@type":"ImageObject","url":"https://Siriuslala.github.io/pig.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://Siriuslala.github.io/ accesskey=h title="Home (Alt + H)"><img src=https://Siriuslala.github.io/apple-touch-icon.png alt aria-label=logo height=35>Home</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://Siriuslala.github.io/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://Siriuslala.github.io/about/ title=About><span>About</span></a></li><li><a href=https://Siriuslala.github.io/archives/ title=Archive><span>Archive</span></a></li><li><a href=https://Siriuslala.github.io/faq/ title=FAQ><span>FAQ</span></a></li><li><a href=https://Siriuslala.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://Siriuslala.github.io/tags/ title=Tags><span>Tags</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://Siriuslala.github.io/>Home</a>&nbsp;¬ª&nbsp;<a href=https://Siriuslala.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">A Brief Introduction to Mechanistic Interpretability Research</h1><div class=post-meta><span title='2024-08-28 13:12:25 +0800 CST'>August 28, 2024</span>&nbsp;¬∑&nbsp;5 min&nbsp;¬∑&nbsp;881 words&nbsp;¬∑&nbsp;Sirius</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><nav id=TableOfContents><ul><li><a href=#1-a-namethepurposeiwritethisblogathe-purpose-i-write-this-blog>1. The purpose I write this blog</a></li><li><a href=#2-a-namewhatismechanisticinterpretabilityawhat-is-mechanistic-interpretability>2. What is Mechanistic interpretability?</a></li><li><a href=#3-a-namebasicideasandresearchtopicsabasic-ideas-and-research-topics>3. Basic ideas and research topics</a><ul><li><a href=#31-a-namefindinterpretablefeaturesafind-interpretable-features>3.1. Find interpretable features</a></li><li><a href=#32-a-namecircuitsacircuits>3.2. Circuits</a></li></ul></li><li><a href=#4-a-namesomeusefulresourcesasome-useful-resources>4. Some Useful Resources</a><ul><li><a href=#41-a-nametutorialsatutorials>4.1. Tutorials</a></li><li><a href=#42-a-nameframeworksandlibrariesaframeworks-and-libraries>4.2. Frameworks and Libraries</a></li><li><a href=#43-a-nameforumsandcommunitiesaforums-and-communities>4.3. Forums and Communities</a></li><li><a href=#44-a-nameinstitutes-and-programsainstitutions-and-programs>4.4. Institutions and Programs</a></li><li><a href=#45-a-nameblogsablogs>4.5. Blogs</a></li></ul></li></ul></nav></div></details></div><div class=post-content><h2 id=1-a-namethepurposeiwritethisblogathe-purpose-i-write-this-blog>1. The purpose I write this blog<a hidden class=anchor aria-hidden=true href=#1-a-namethepurposeiwritethisblogathe-purpose-i-write-this-blog>#</a></h2><p>‚ÄÇ ‚ÄÇMechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc). Thus it&rsquo;s a little bit difficult for people new to this area to figure out what researchers are really doing.<br>‚ÄÇ ‚ÄÇTherefore I write this blog to give a brief introduction to mechanistic interpretability without so much of horrible concepts. The blog aims to help you understand the <strong>basic ideas, main directions and latest achievements</strong> of this field, providing <strong>a list of resources</strong> to help you get started at the same time!</p><h2 id=2-a-namewhatismechanisticinterpretabilityawhat-is-mechanistic-interpretability>2. What is Mechanistic interpretability?<a hidden class=anchor aria-hidden=true href=#2-a-namewhatismechanisticinterpretabilityawhat-is-mechanistic-interpretability>#</a></h2><p>‚ÄÇ‚ÄÇSpeaking of AI research, neural network is the tool that is used most widely nowadays for its excellent representation and generalization ability. What does a neural network do? It receives an input and gives an output after some calculations. Specifically speaking, it usually gets the representations of an input and maps it to an expected output under a predefined computation graph. From my perspective, neural networks mainly care about two things: create representations to extract features and establishe the relationship between the representations and the output.<br>‚ÄÇ‚ÄÇWhy is neural network so popular? An important reason is that the neural network can save a lot of time for researchers to <strong>manually</strong> design features. For example, for natural language processing (NLP) people often designed features like &ldquo;the frequency of a word that appears&rdquo; or &ldquo;the co-occurence probabilities&rdquo; in the past. Manually designing features caused too much labor, so people choose to use neural networks to find features automatically. As for optimizing, they set a goal of minimizing the loss function and using backforward propagation (BP) to update the parameters of the model. Thus neural networks free our hands and improve performance at the same time.<br>‚ÄÇ‚ÄÇ All is well, so why do we concern about interpretability? Though neural networks can extract a lot of features with a high efficiency, we cannot have a clear understanding of what the features really are. For example, we know that a filter with Laplacian operator can extract the edge of an image, but we don&rsquo;t know what the features extracted by a convolution layer mean because the parameters of the filters inside are often randomly initialized and optimized using BP algorithm. As a result, features in neural networks are often ambiguous.<br>‚ÄÇ‚ÄÇ Why is interpretability important? Actually this statement is controversial because some people say interpretability is bullshit&#x1f4a9;. I&rsquo;m not angry about this. Anyway, people&rsquo;s taste varies, just like many people enjoy Picasso&rsquo;s abstract paintings while I don&rsquo;t. Interpretabilty still lacks exploring so it&rsquo;s now far from application, and that&rsquo;s why some people look down on it. While it is this lack of exploration that excites me most because there are a lot of unknown things waiting for me to discover! Apart from that, interpretabilty is closely related to <strong>AI safety</strong> because unwanted things like malicious text generated by a language model may be avoided using model steering (a trick using interpretability).<br>‚ÄÇ‚ÄÇLast question: what is mechanistic interpretability? Let&rsquo;s call it mech interp first because I&rsquo;m really tired of typing the full name&#x1f4a6;. There seems not to be a rigorous definition, but I here I want to quote the explanation by <a href=https://transformer-circuits.pub/2022/mech-interp-essay/index.html>Chiris Olah</a>:</p><p>‚ÄÇ‚ÄÇ<em>Mechanistic interpretability seeks to reverse engineer neural networks, similar to how one might reverse engineer a compiled binary computer program.</em></p><p>‚ÄÇ‚ÄÇAnother thing: there are various of categories of interpretability, such as studies from the geometry perspective or from the game theory and symbol system perspective, which can be found at ICML, ICLR, NeurlPS, etc. When we say mech interp, we often refer to the studies on Transformer-based generative language models now (though the research started before 2017) which will be introduced briefly in the next section.</p><h2 id=3-a-namebasicideasandresearchtopicsabasic-ideas-and-research-topics>3. Basic ideas and research topics<a hidden class=anchor aria-hidden=true href=#3-a-namebasicideasandresearchtopicsabasic-ideas-and-research-topics>#</a></h2><h3 id=31-a-namefindinterpretablefeaturesafind-interpretable-features>3.1. Find interpretable features<a hidden class=anchor aria-hidden=true href=#31-a-namefindinterpretablefeaturesafind-interpretable-features>#</a></h3><h3 id=32-a-namecircuitsacircuits>3.2. Circuits<a hidden class=anchor aria-hidden=true href=#32-a-namecircuitsacircuits>#</a></h3><h2 id=4-a-namesomeusefulresourcesasome-useful-resources>4. Some Useful Resources<a hidden class=anchor aria-hidden=true href=#4-a-namesomeusefulresourcesasome-useful-resources>#</a></h2><p>Here I list some resources that would be helpful for you to get started quickly in the field.</p><h3 id=41-a-nametutorialsatutorials>4.1. Tutorials<a hidden class=anchor aria-hidden=true href=#41-a-nametutorialsatutorials>#</a></h3><ul><li><strong><a href=https://arena3-chapter1-transformer-interp.streamlit.app/#about-this-page>Arena</a></strong>‚ÄÇ‚ÄÇ A tutorial created and maintained by Callum McDougall et al, providing a guided path for anyone who finds themselves overwhelmed by the amount of technical AI safety content out there.</li><li><strong><a href=https://www.neelnanda.io/mechanistic-interpretability/getting-started>Neel Nanda&rsquo;s Tutorial</a></strong>‚ÄÇ‚ÄÇ Neel&rsquo;s tutorial for mech interp.</li><li><strong><a href=https://www.alignmentforum.org/posts/jLAvJt8wuSFySN975/mechanistic-interpretability-quickstart-guide>Neel Nanda&rsquo;s Quickstart Guide</a></strong>‚ÄÇ‚ÄÇ A quick start for mech interp.</li><li><strong><a href=https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite-1>Neel Nanda&rsquo;s remommended papers</a></strong>‚ÄÇ‚ÄÇ Some classic and important papers for mech interp.</li><li><strong><a href=https://www.alignmentforum.org/posts/LbrPTJ4fmABEdEnLf/200-concrete-open-problems-in-mechanistic-interpretability>Neel Nanda&rsquo;s problems v1</a></strong>‚ÄÇ‚ÄÇ Neel&rsquo;s old questions for mech interp.</li><li><strong><a href="https://www.google.com/url?q=https%3A%2F%2Fdocs.google.com%2Fdocument%2Fd%2F1lIIzMjenXh-U0j5jkuqSDTawCoMNW4TqUlxk7mmbmRg%2Fedit">Neel Nanda&rsquo;s problems v2</a></strong>‚ÄÇ‚ÄÇ Neel&rsquo;s 200 new questions for mech interp.
<strong><a href></a></strong>‚ÄÇ‚ÄÇ<br><strong><a href></a></strong>‚ÄÇ‚ÄÇ</li></ul><h3 id=42-a-nameframeworksandlibrariesaframeworks-and-libraries>4.2. Frameworks and Libraries<a hidden class=anchor aria-hidden=true href=#42-a-nameframeworksandlibrariesaframeworks-and-libraries>#</a></h3><ul><li><p><strong><a href=https://transformerlensorg.github.io/TransformerLens/>TransformerLens</a></strong>‚ÄÇ‚ÄÇA library maintained by Bryce Meyer and created by Neel Nanda.</p></li><li><p><strong><a href=%E2%80%82%E2%80%82>SAELens</a></strong>‚ÄÇ‚ÄÇOriginates from TransformerLens, and is separated from it because of the popularity and importance of SAE.</p></li></ul><h3 id=43-a-nameforumsandcommunitiesaforums-and-communities>4.3. Forums and Communities<a hidden class=anchor aria-hidden=true href=#43-a-nameforumsandcommunitiesaforums-and-communities>#</a></h3><ul><li><strong><a href=https://transformer-circuits.pub/>Transformer Circuits Thread</a></strong>‚ÄÇ‚ÄÇ The research posts of Anthropic alignment group.</li><li><strong><a href=https://www.lesswrong.com/>Lesswrong</a></strong>‚ÄÇ‚ÄÇ</li><li><strong><a href=https://www.alignmentforum.org/>AI Alignment Forum</a></strong>‚ÄÇ‚ÄÇ<br><strong><a href></a></strong>‚ÄÇ‚ÄÇ</li></ul><h3 id=44-a-nameinstitutes-and-programsainstitutions-and-programs>4.4. Institutions and Programs<a hidden class=anchor aria-hidden=true href=#44-a-nameinstitutes-and-programsainstitutions-and-programs>#</a></h3><ul><li><strong><a href=https://www.matsprogram.org/>MATS</a></strong>‚ÄÇ‚ÄÇ An independent research and educational seminar program that connects talented scholars with top mentors in the fields of AI alignment, interpretability, and governance.</li><li><strong><a href=https://www.redwoodresearch.org/>RedWood</a></strong>‚ÄÇ‚ÄÇ<br><strong><a href></a></strong>‚ÄÇ‚ÄÇ</li></ul><h3 id=45-a-nameblogsablogs>4.5. Blogs<a hidden class=anchor aria-hidden=true href=#45-a-nameblogsablogs>#</a></h3><p><strong><a href=https://colah.github.io/>Chris Olah</a></strong>‚ÄÇ‚ÄÇ<br><strong><a href=https://www.neelnanda.io/>Neel Nanda</a></strong>‚ÄÇ‚ÄÇ<br><strong><a href=https://arthurconmy.github.io/>Arthur Conmy</a></strong>‚ÄÇ‚ÄÇ<br><strong><a href=https://www.trentonbricken.com/>Trenton Bricken</a></strong>‚ÄÇ‚ÄÇ<br><strong><a href=https://www.perfectlynormal.co.uk/>Callum Mcdougall</a></strong>‚ÄÇ‚ÄÇ<br><strong><a href></a></strong>‚ÄÇ‚ÄÇ</p><p>&mldr;</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://Siriuslala.github.io/tags/mechanistic-interpretability/>Mechanistic Interpretability</a></li><li><a href=https://Siriuslala.github.io/tags/machine-learning/>Machine Learning</a></li></ul><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Introduction to Mechanistic Interpretability Research on x" href="https://x.com/intent/tweet/?text=A%20Brief%20Introduction%20to%20Mechanistic%20Interpretability%20Research&amp;url=https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f&amp;hashtags=mechanisticinterpretability%2cmachinelearning"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Introduction to Mechanistic Interpretability Research on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f&amp;title=A%20Brief%20Introduction%20to%20Mechanistic%20Interpretability%20Research&amp;summary=A%20Brief%20Introduction%20to%20Mechanistic%20Interpretability%20Research&amp;source=https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Introduction to Mechanistic Interpretability Research on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f&title=A%20Brief%20Introduction%20to%20Mechanistic%20Interpretability%20Research"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Introduction to Mechanistic Interpretability Research on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Introduction to Mechanistic Interpretability Research on whatsapp" href="https://api.whatsapp.com/send?text=A%20Brief%20Introduction%20to%20Mechanistic%20Interpretability%20Research%20-%20https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Introduction to Mechanistic Interpretability Research on telegram" href="https://telegram.me/share/url?text=A%20Brief%20Introduction%20to%20Mechanistic%20Interpretability%20Research&amp;url=https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share A Brief Introduction to Mechanistic Interpretability Research on ycombinator" href="https://news.ycombinator.com/submitlink?t=A%20Brief%20Introduction%20to%20Mechanistic%20Interpretability%20Research&u=https%3a%2f%2fSiriuslala.github.io%2fposts%2fmech_inrterp_resource%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentcolor" xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>&copy; 2024 <a href=https://Siriuslala.github.io/>Siriuslala's Blog!</a></span> ¬∑
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script></body></html>
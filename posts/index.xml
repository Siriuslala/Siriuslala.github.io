<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Siriuslala&#39;s Blog!</title>
    <link>https://Siriuslala.github.io/posts/</link>
    <description>Recent content in Posts on Siriuslala&#39;s Blog!</description>
    <image>
      <title>Siriuslala&#39;s Blog!</title>
      <url>https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</url>
      <link>https://Siriuslala.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E</link>
    </image>
    <generator>Hugo -- 0.147.6</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 25 Feb 2025 15:08:53 +0800</lastBuildDate>
    <atom:link href="https://Siriuslala.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>MM_Interp</title>
      <link>https://Siriuslala.github.io/posts/mm_interp/</link>
      <pubDate>Tue, 25 Feb 2025 15:08:53 +0800</pubDate>
      <guid>https://Siriuslala.github.io/posts/mm_interp/</guid>
      <description>&lt;h2 id=&#34;resource&#34;&gt;Resource&lt;/h2&gt;
&lt;h2 id=&#34;analyses-on-mllms&#34;&gt;Analyses on MLLMs&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;dataset&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1902.09506&#34;&gt;(GQA) GQA:ANewDataset for Real-World Visual Reasoning and Compositional Question Answering&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cs.stanford.edu/people/dorarad/gqa/index.html&#34;&gt;https://cs.stanford.edu/people/dorarad/gqa/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;image token compression&lt;/strong&gt;&lt;br&gt;
(multimodal image token compression)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2501.09532&#34;&gt;*AdaFV: Rethinking of Visual-Language alignment for VLM acceleration&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2412.01818&#34;&gt;(FasterVLM) [CLS] Attention is All You Need for Training-FreeVisual Token Pruning: Make VLM Inference Faster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2410.04417&#34;&gt;Sparsevlm: Visual token sparsification for efficient vision-languag&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2403.06764&#34;&gt;(FastV) An image is worth 1/2 tokens after layer 2: Plug-and-PLay Acceleration for VLLM Inference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2501.03895&#34;&gt;LLaVA-Mini: Efficient Image and Video Large Multimodal Models with One Vision Token&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2411.03312&#34;&gt;*Inference Optimal VLMs Need Only One Visual Token but Larger Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2407.02392&#34;&gt;TokenPacker: Efficient Visual Projector for Multimodal LLM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2405.17430&#34;&gt;Matryoshka Multimodal Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2405.19315&#34;&gt;Matryoshka Query Transformer for Large Vision-Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2412.04317&#34;&gt;FlashSloth: Lightning Multimodal Large Language Models via Embedded Visual Compression&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2501.16297&#34;&gt;FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2407.14439&#34;&gt;Token-level Correlation-guided Compression for Efficient Multimodal Document Understanding&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;spatial&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Circuit-tuning: A Mechanistic Approach for Identifying Parameter Redundancy and Fine-tuning Neural Networks</title>
      <link>https://Siriuslala.github.io/posts/circuit_tuning/</link>
      <pubDate>Wed, 05 Feb 2025 16:22:33 +0800</pubDate>
      <guid>https://Siriuslala.github.io/posts/circuit_tuning/</guid>
      <description>&lt;p&gt;The &lt;a href=&#34;https://Siriuslala.github.io/pdfs/circuit_tuning&#34;&gt;paper&lt;/a&gt; is here.&lt;/p&gt;
&lt;p&gt;ArXiv: &lt;a href=&#34;https://arxiv.org/pdf/2502.06106&#34;&gt;https://arxiv.org/pdf/2502.06106&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>一些语言学的梗和有意思的知识</title>
      <link>https://Siriuslala.github.io/posts/%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E5%AD%A6%E7%9A%84%E6%A2%97%E5%92%8C%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E7%9F%A5%E8%AF%86/</link>
      <pubDate>Fri, 27 Sep 2024 17:15:10 +0800</pubDate>
      <guid>https://Siriuslala.github.io/posts/%E4%B8%80%E4%BA%9B%E8%AF%AD%E8%A8%80%E5%AD%A6%E7%9A%84%E6%A2%97%E5%92%8C%E6%9C%89%E6%84%8F%E6%80%9D%E7%9A%84%E7%9F%A5%E8%AF%86/</guid>
      <description>&lt;p&gt;This post is written in Chinese. If you don&amp;rsquo;t know Chinese, you can learn it lol. (Sorry for this because simply translating the post into English may not be enough for you to understand).&lt;/p&gt;
&lt;h2 id=&#34;纯玩梗&#34;&gt;纯玩梗&lt;/h2&gt;
&lt;h2 id=&#34;语言现象背后蕴含的知识&#34;&gt;语言现象背后蕴含的知识&lt;/h2&gt;
&lt;h3 id=&#34;皮钦语-pidgin&#34;&gt;皮钦语 (pidgin)&lt;/h3&gt;
&lt;p&gt;大家对那些 1.言语中不时夹杂着英文单词 2.装/凡尔赛 的人表现出一种厌恶。例如，下面是某恋综里的一段名场面：&lt;/p&gt;</description>
    </item>
    <item>
      <title>Possible Research Areas in Mechanistic Interpretability</title>
      <link>https://Siriuslala.github.io/posts/mech_interp_research/</link>
      <pubDate>Fri, 06 Sep 2024 22:52:16 +0800</pubDate>
      <guid>https://Siriuslala.github.io/posts/mech_interp_research/</guid>
      <description>&lt;h2 id=&#34;the-purpose-i-write-this-blog&#34;&gt;The Purpose I Write This Blog&lt;/h2&gt;
&lt;p&gt;   To get started in mech interp research, we need to have a macro understanding of this area. So I write this blog as a summarization of this field to help you and me choose a research topic.&lt;/p&gt;
&lt;h2 id=&#34;circuit-discovery&#34;&gt;Circuit Discovery&lt;/h2&gt;
&lt;h3 id=&#34;methods&#34;&gt;Methods&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;basic&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;activation patching (causal mediation/interchange interventions&amp;hellip;)&lt;/li&gt;
&lt;li&gt;path patching&lt;/li&gt;
&lt;li&gt;scaling techinques: attribution patching&lt;/li&gt;
&lt;li&gt;DAS (distributed alignment search)   directional activation patching?&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&#34;telescope-resources&#34;&gt;&amp;#x1f52d; resources&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;inspirition
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1905.09418&#34;&gt;Analyzing Multi-Head Self-Attention: Specialized Heads Do the Heavy Lifting, the Rest Can Be Pruned&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2202.05262&#34;&gt;(ROME) Locating and Editing Factual Associations in GPT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.neelnanda.io/mechanistic-interpretability/attribution-patching&#34;&gt;Attribution patching: Activation patching at industrial scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2304.14997&#34;&gt;(ACDC) Towards Automated Circuit Discovery for Mechanistic Interpretability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2310.10348&#34;&gt;Attribution Patching Outperforms Automated Circuit Discovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2403.00745&#34;&gt;AtP*: An efficient and scalable method for localizing llm behaviour to components&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.alignmentforum.org/posts/JvZhhzycHu2Yd57RN/causal-scrubbing-a-method-for-rigorously-testing&#34;&gt;Causal Scrubbing: a method for rigorously testing interpretability hypotheses&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;new&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Using SAE
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2403.19647&#34;&gt;Sparse Feature Circuits: Discovering and Editing Interpretable Causal Graphs in Language Models&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2405.13868&#34;&gt;Automatically Identifying Local and Global Circuits with Linear Computation Graphs&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Contextual Decomposition
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.00886&#34;&gt;Mechanistic Interpretation through Contextual Decomposition in Transformers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Edge Pruning ?
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2406.16778&#34;&gt;Finding Transformer Circuits with Edge Pruning&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.03779&#34;&gt;Functional Faithfulness in the Wild: Circuit Discovery with Differentiable Computation Graph Pruning&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;&#34;&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h3&gt;
&lt;p&gt;lack of ground truth&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Emotional Features in GPT2-Small</title>
      <link>https://Siriuslala.github.io/posts/happy_feats/</link>
      <pubDate>Thu, 29 Aug 2024 15:51:59 +0800</pubDate>
      <guid>https://Siriuslala.github.io/posts/happy_feats/</guid>
      <description>&lt;p&gt;&amp;#x1f3b6;Code in this post can be found at &lt;a href=&#34;https://github.com/Siriuslala/saeExploration/blob/main/multilingual_study.ipynb&#34;&gt;the jupyter notebook in my &amp;ldquo;saeExploration&amp;rdquo; repo&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&#34;find-features-that-reflect-positive-emotions&#34;&gt;Find features that reflect positive emotions&lt;/h2&gt;
&lt;p&gt;To find the features related to a specific emotion, I write five sentences containing the key words for each emotion. For example, for happy emotions I have:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;div class=&#34;chroma&#34;&gt;
&lt;table class=&#34;lntable&#34;&gt;&lt;tr&gt;&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-1&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-1&#34;&gt;1&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-2&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-2&#34;&gt;2&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-3&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-3&#34;&gt;3&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-4&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-4&#34;&gt;4&lt;/a&gt;
&lt;/span&gt;&lt;span class=&#34;lnt&#34; id=&#34;hl-0-5&#34;&gt;&lt;a class=&#34;lnlinks&#34; href=&#34;#hl-0-5&#34;&gt;5&lt;/a&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;
&lt;td class=&#34;lntd&#34;&gt;
&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;n&#34;&gt;prompt_happy&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;ll be on a vacation tomorrow and I&amp;#39;m so happy.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;My mombrings home a new puppy and I&amp;#39;m so happy.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;m so glad I got the job I wanted.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;I feel so happy when I&amp;#39;m with my friends.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span class=&#34;line&#34;&gt;&lt;span class=&#34;cl&#34;&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;I&amp;#39;m so happy I got the promotion I wanted.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,]&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;p&gt;I choose to look for features that reflect happiness and sadness. Apart from that, I also wonder if the feature that reflects excitedness has something to do with the one that reflects happiness (they are alike from the semantic level at least.)&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Brief Introduction to Mechanistic Interpretability Research</title>
      <link>https://Siriuslala.github.io/posts/mech_interp_resource/</link>
      <pubDate>Wed, 28 Aug 2024 13:12:25 +0800</pubDate>
      <guid>https://Siriuslala.github.io/posts/mech_interp_resource/</guid>
      <description>&lt;h2 id=&#34;the-purpose-i-write-this-blog&#34;&gt;The purpose I write this blog&lt;/h2&gt;
&lt;p&gt;Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challenges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc). Thus it&amp;rsquo;s a little bit difficult for people new to this area to figure out what researchers are really doing.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>

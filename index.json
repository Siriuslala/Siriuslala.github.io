[{"content":"1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc). Thus it\u0026rsquo;s a little bit difficult for people new to this area to figure out what researchers are really doing.\nTherefore I write this blog to give a brief introduction to mechanistic interpretability without so much of horrible concepts. The blog aims to help you understand the basic ideas, main directions and latest achievements of this field, providing a list of resources to help you get started at the same time!\n2. What is Mechanistic interpretability? Speaking of AI research, neural network is the tool that is used most widely nowadays for its excellent representation and generalization ability. What does a neural network do? It receives an input and gives an output after some calculations. Specifically speaking, it usually gets the representations of an input and maps it to an expected output under a predefined computation graph. From my perspective, neural networks mainly care about two things: create representations to extract features and establishe the relationship between the representations and the output. Why is neural network so popular? An important reason is that the neural network can save a lot of time for researchers to manually design features. For example, for natural language processing (NLP) people often designed features like \u0026ldquo;the frequency of a word that appears\u0026rdquo; or \u0026ldquo;the co-occurence probabilities\u0026rdquo; in the past. Manually designing features caused too much labor, so people choose to use neural networks to find features automatically. As for optimizing, they set a goal of minimizing the loss function and using backforward propagation (BP) to update the parameters of the model. Thus neural networks free our hands and improve performance at the same time.\nAll is well, so why do we concern about interpretability? Though neural networks can extract a lot of features with a high efficiency, we cannot have a clear understanding of what the features really are. For example, we know that a filter with Laplacian operator can extract the edge of an image, but we don\u0026rsquo;t know what the features extracted by a convolution layer mean because the parameters of the filters inside are often randomly initialized and optimized using BP algorithm. As a result, features in neural networks are often ambiguous.\nWhy is interpretability important? Actually this statement is controversial because some people say interpretability is bullshit\u0026#x1f4a9;. I\u0026rsquo;m not angry about this. Anyway, people\u0026rsquo;s taste varies, just like many people enjoy Picasso\u0026rsquo;s abstract paintings while I don\u0026rsquo;t. Interpretabilty still lacks exploring so it\u0026rsquo;s now far from application, and that\u0026rsquo;s why some people look down on it. While it is this lack of exploration that excites me most because there are a lot of unknown things waiting for me to discover! Apart from that, interpretabilty is closely related to AI safety because unwanted things like malicious text generated by a language model may be avoided using model steering (a trick using interpretability).\nLast question: what is mechanistic interpretability? Let\u0026rsquo;s call it mech interp first because I\u0026rsquo;m really tired of typing the full name\u0026#x1f4a6;. There seems not to be a rigorous definition, but I here I want to quote the explanation by Chiris Olah:\nMechanistic interpretability seeks to reverse engineer neural networks, similar to how one might reverse engineer a compiled binary computer program.\nAnother thing: there are various of categories of interpretability, such as studies from the geometry perspective or from the game theory and symbol system perspective, which can be found at ICML, ICLR, NeurlPS, etc. When speaking mech interp, we often refer to the studies on Transformer-based generative language models now (though the research started before 2017) which will be introduced briefly in the next section.\n3. Basic ideas and research topics 3.1. Find interpretable features 3.2. Circuits 4. Some Useful Resources Here I list some resources that would be helpful for you to get started quickly in the field.\n4.1. Tutorials Arena A tutorial created and maintained by Callum McDougall et al, providing a guided path for anyone who finds themselves overwhelmed by the amount of technical AI safety content out there. Neel Nanda\u0026rsquo;s Tutorial Neel\u0026rsquo;s tutorial for mech interp. Neel Nanda\u0026rsquo;s Quickstart Guide A quick start for mech interp. Neel Nanda\u0026rsquo;s remommended papers Some classic and important papers for mech interp. Neel Nanda\u0026rsquo;s problems v1 Neel\u0026rsquo;s old questions for mech interp. Neel Nanda\u0026rsquo;s problems v2 Neel\u0026rsquo;s 200 new questions for mech interp. 4.2. Frameworks and Libraries TransformerLens A library maintained by Bryce Meyer and created by Neel Nanda.\nSAELens Originates from TransformerLens, and is separated from it because of the popularity and importance of SAE.\n4.3. Forums and Communities Transformer Circuits Thread The research posts of Anthropic alignment group. Lesswrong AI Alignment Forum 4.4. Institutions and Programs MATS An independent research and educational seminar program that connects talented scholars with top mentors in the fields of AI alignment, interpretability, and governance. RedWood 4.5. Blogs Chris Olah Neel Nanda Arthur Conmy Trenton Bricken Callum Mcdougall \u0026hellip;\n","permalink":"https://Siriuslala.github.io/posts/mech_inrterp_resource/","summary":"1. The purpose I write this blog Mechanistic Interpretability is a new field in machine learning that aims to reverse engineering complicated model structures to something clear, understandable and hopefully controllable for our humans. The study of this field is still at a young age and facing mountains of challanges. While for beginners (like me), there are lots of terms or ideas which are not so familiar (e.g. superposition, circuits, activation patching, etc).","title":"A Brief Introduction to Mechanistic Interpretability Research"},{"content":"Who am I? Hi~ I\u0026rsquo;m Yueyan Li, a researcher(still a student now) in China. I\u0026rsquo;m now at the Center of Intelligence Science and Technology, BUPT. My research focuses on machine learning, deep learning and natural language processing, mainly mechanistic interpretability now! Here is my CV.\nExcept from my research area, I\u0026rsquo;m also interested in communication engineering\u0026#x1f4fb; which was my major when I was an undergraduate. If you like that, feel free to share something interesting together~\nApart from technologies, I\u0026rsquo;m a lover for nature. I like the mountains, the rivers, the forests\u0026hellip;if you like hiking outdoors, don\u0026rsquo;t forget me! Also, I\u0026rsquo;m a Bboy\u0026#x270c;\u0026#xfe0f;\u0026#x1f918;. If you like breaking or any kind of street dance, just call me\u0026#x1f44b;!\nSometimes I paint as a waste of time, though I\u0026rsquo;m not professional.\nAbout my nickname I use the name Sirius/Sirius Jr./siriuslala\u0026hellip; everywhere on the Internet. This originates from Sirius Black-my favourite character in the Harry Potter series.\nHe is not only an extraodinary wizard with wild and intractable appearence but also the godfather of Harry Potter-the only family alive for Harry who had brought him warmth that is hard to replace. That\u0026rsquo;s why I admire him.\n","permalink":"https://Siriuslala.github.io/about/","summary":"About myself","title":"About Myself"},{"content":"","permalink":"https://Siriuslala.github.io/faq/","summary":"faq","title":"faq"},{"content":"\rPrevious\rNext \u0026nbsp; \u0026nbsp;\r/ [pdf]\rView the PDF file here.\r","permalink":"https://Siriuslala.github.io/helper/","summary":"\rPrevious\rNext \u0026nbsp; \u0026nbsp;\r/ [pdf]\rView the PDF file here.\r","title":"Yueyan Li"}]